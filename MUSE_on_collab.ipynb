{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MUSE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa9yGHG-HgnI",
        "colab_type": "code",
        "outputId": "9800ff64-5e71-4aba-b028-636066f81e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "! git clone https://github.com/anuragvij264/MUSE.git\n",
        "! mv  MUSE/* ./"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MUSE'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "Receiving objects:   0% (1/247)   \rReceiving objects:   1% (3/247)   \rReceiving objects:   2% (5/247)   \rReceiving objects:   3% (8/247)   \rReceiving objects:   4% (10/247)   \rReceiving objects:   5% (13/247)   \rReceiving objects:   6% (15/247)   \rReceiving objects:   7% (18/247)   \rReceiving objects:   8% (20/247)   \rReceiving objects:   9% (23/247)   \rReceiving objects:  10% (25/247)   \rReceiving objects:  11% (28/247)   \rReceiving objects:  12% (30/247)   \rReceiving objects:  13% (33/247)   \rReceiving objects:  14% (35/247)   \rReceiving objects:  15% (38/247)   \rReceiving objects:  16% (40/247)   \rReceiving objects:  17% (42/247)   \rReceiving objects:  18% (45/247)   \rReceiving objects:  19% (47/247)   \rReceiving objects:  20% (50/247)   \rReceiving objects:  21% (52/247)   \rReceiving objects:  22% (55/247)   \rReceiving objects:  23% (57/247)   \rReceiving objects:  24% (60/247)   \rReceiving objects:  25% (62/247)   \rReceiving objects:  26% (65/247)   \rReceiving objects:  27% (67/247)   \rReceiving objects:  28% (70/247)   \rReceiving objects:  29% (72/247)   \rReceiving objects:  30% (75/247)   \rReceiving objects:  31% (77/247)   \rReceiving objects:  32% (80/247)   \rReceiving objects:  33% (82/247)   \rReceiving objects:  34% (84/247)   \rReceiving objects:  35% (87/247)   \rReceiving objects:  36% (89/247)   \rReceiving objects:  37% (92/247)   \rReceiving objects:  38% (94/247)   \rReceiving objects:  39% (97/247)   \rReceiving objects:  40% (99/247)   \rReceiving objects:  41% (102/247)   \rReceiving objects:  42% (104/247)   \rReceiving objects:  43% (107/247)   \rReceiving objects:  44% (109/247)   \rReceiving objects:  45% (112/247)   \rReceiving objects:  46% (114/247)   \rReceiving objects:  47% (117/247)   \rReceiving objects:  48% (119/247)   \rReceiving objects:  49% (122/247)   \rReceiving objects:  50% (124/247)   \rReceiving objects:  51% (126/247)   \rReceiving objects:  52% (129/247)   \rReceiving objects:  53% (131/247)   \rReceiving objects:  54% (134/247)   \rReceiving objects:  55% (136/247)   \rReceiving objects:  56% (139/247)   \rReceiving objects:  57% (141/247)   \rReceiving objects:  58% (144/247)   \rReceiving objects:  59% (146/247)   \rReceiving objects:  60% (149/247)   \rReceiving objects:  61% (151/247)   \rReceiving objects:  62% (154/247)   \rReceiving objects:  63% (156/247)   \rReceiving objects:  64% (159/247)   \rReceiving objects:  65% (161/247)   \rReceiving objects:  66% (164/247)   \rReceiving objects:  67% (166/247)   \rReceiving objects:  68% (168/247)   \rReceiving objects:  69% (171/247)   \rReceiving objects:  70% (173/247)   \rReceiving objects:  71% (176/247)   \rReceiving objects:  72% (178/247)   \rReceiving objects:  73% (181/247)   \rReceiving objects:  74% (183/247)   \rReceiving objects:  75% (186/247)   \rReceiving objects:  76% (188/247)   \rReceiving objects:  77% (191/247)   \rReceiving objects:  78% (193/247)   \rReceiving objects:  79% (196/247)   \rReceiving objects:  80% (198/247)   \rReceiving objects:  81% (201/247)   \rReceiving objects:  82% (203/247)   \rReceiving objects:  83% (206/247)   \rReceiving objects:  84% (208/247)   \rReceiving objects:  85% (210/247)   \rReceiving objects:  86% (213/247)   \rReceiving objects:  87% (215/247)   \rReceiving objects:  88% (218/247)   \rReceiving objects:  89% (220/247)   \rReceiving objects:  90% (223/247)   \rReceiving objects:  91% (225/247)   \rReceiving objects:  92% (228/247)   \rReceiving objects:  93% (230/247)   \rReceiving objects:  94% (233/247)   \rReceiving objects:  95% (235/247)   \rReceiving objects:  96% (238/247)   \rremote: Total 247 (delta 0), reused 2 (delta 0), pack-reused 241\u001b[K\n",
            "Receiving objects:  97% (240/247)   \rReceiving objects:  98% (243/247)   \rReceiving objects:  99% (245/247)   \rReceiving objects: 100% (247/247)   \rReceiving objects: 100% (247/247), 562.95 KiB | 2.29 MiB/s, done.\n",
            "Resolving deltas:   0% (0/137)   \rResolving deltas:   6% (9/137)   \rResolving deltas:   8% (11/137)   \rResolving deltas:   9% (13/137)   \rResolving deltas:  12% (17/137)   \rResolving deltas:  13% (18/137)   \rResolving deltas:  15% (21/137)   \rResolving deltas:  24% (33/137)   \rResolving deltas:  38% (53/137)   \rResolving deltas:  40% (56/137)   \rResolving deltas:  45% (62/137)   \rResolving deltas:  50% (69/137)   \rResolving deltas:  51% (71/137)   \rResolving deltas:  52% (72/137)   \rResolving deltas:  66% (91/137)   \rResolving deltas:  70% (97/137)   \rResolving deltas:  74% (102/137)   \rResolving deltas:  78% (107/137)   \rResolving deltas:  86% (118/137)   \rResolving deltas:  89% (122/137)   \rResolving deltas:  94% (129/137)   \rResolving deltas:  97% (133/137)   \rResolving deltas: 100% (137/137)   \rResolving deltas: 100% (137/137), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7RCelJ3Xty0",
        "colab_type": "code",
        "outputId": "ff0fb7b7-26b1-4359-fbc6-6a88872c34d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/122)\u001b[K\rremote: Counting objects:   1% (2/122)\u001b[K\rremote: Counting objects:   2% (3/122)\u001b[K\rremote: Counting objects:   3% (4/122)\u001b[K\rremote: Counting objects:   4% (5/122)\u001b[K\rremote: Counting objects:   5% (7/122)\u001b[K\rremote: Counting objects:   6% (8/122)\u001b[K\rremote: Counting objects:   7% (9/122)\u001b[K\rremote: Counting objects:   8% (10/122)\u001b[K\rremote: Counting objects:   9% (11/122)\u001b[K\rremote: Counting objects:  10% (13/122)\u001b[K\rremote: Counting objects:  11% (14/122)\u001b[K\rremote: Counting objects:  12% (15/122)\u001b[K\rremote: Counting objects:  13% (16/122)\u001b[K\rremote: Counting objects:  14% (18/122)\u001b[K\rremote: Counting objects:  15% (19/122)\u001b[K\rremote: Counting objects:  16% (20/122)\u001b[K\rremote: Counting objects:  17% (21/122)\u001b[K\rremote: Counting objects:  18% (22/122)\u001b[K\rremote: Counting objects:  19% (24/122)\u001b[K\rremote: Counting objects:  20% (25/122)\u001b[K\rremote: Counting objects:  21% (26/122)\u001b[K\rremote: Counting objects:  22% (27/122)\u001b[K\rremote: Counting objects:  23% (29/122)\u001b[K\rremote: Counting objects:  24% (30/122)\u001b[K\rremote: Counting objects:  25% (31/122)\u001b[K\rremote: Counting objects:  26% (32/122)\u001b[K\rremote: Counting objects:  27% (33/122)\u001b[K\rremote: Counting objects:  28% (35/122)\u001b[K\rremote: Counting objects:  29% (36/122)\u001b[K\rremote: Counting objects:  30% (37/122)\u001b[K\rremote: Counting objects:  31% (38/122)\u001b[K\rremote: Counting objects:  32% (40/122)\u001b[K\rremote: Counting objects:  33% (41/122)\u001b[K\rremote: Counting objects:  34% (42/122)\u001b[K\rremote: Counting objects:  35% (43/122)\u001b[K\rremote: Counting objects:  36% (44/122)\u001b[K\rremote: Counting objects:  37% (46/122)\u001b[K\rremote: Counting objects:  38% (47/122)\u001b[K\rremote: Counting objects:  39% (48/122)\u001b[K\rremote: Counting objects:  40% (49/122)\u001b[K\rremote: Counting objects:  41% (51/122)\u001b[K\rremote: Counting objects:  42% (52/122)\u001b[K\rremote: Counting objects:  43% (53/122)\u001b[K\rremote: Counting objects:  44% (54/122)\u001b[K\rremote: Counting objects:  45% (55/122)\u001b[K\rremote: Counting objects:  46% (57/122)\u001b[K\rremote: Counting objects:  47% (58/122)\u001b[K\rremote: Counting objects:  48% (59/122)\u001b[K\rremote: Counting objects:  49% (60/122)\u001b[K\rremote: Counting objects:  50% (61/122)\u001b[K\rremote: Counting objects:  51% (63/122)\u001b[K\rremote: Counting objects:  52% (64/122)\u001b[K\rremote: Counting objects:  53% (65/122)\u001b[K\rremote: Counting objects:  54% (66/122)\u001b[K\rremote: Counting objects:  55% (68/122)\u001b[K\rremote: Counting objects:  56% (69/122)\u001b[K\rremote: Counting objects:  57% (70/122)\u001b[K\rremote: Counting objects:  58% (71/122)\u001b[K\rremote: Counting objects:  59% (72/122)\u001b[K\rremote: Counting objects:  60% (74/122)\u001b[K\rremote: Counting objects:  61% (75/122)\u001b[K\rremote: Counting objects:  62% (76/122)\u001b[K\rremote: Counting objects:  63% (77/122)\u001b[K\rremote: Counting objects:  64% (79/122)\u001b[K\rremote: Counting objects:  65% (80/122)\u001b[K\rremote: Counting objects:  66% (81/122)\u001b[K\rremote: Counting objects:  67% (82/122)\u001b[K\rremote: Counting objects:  68% (83/122)\u001b[K\rremote: Counting objects:  69% (85/122)\u001b[K\rremote: Counting objects:  70% (86/122)\u001b[K\rremote: Counting objects:  71% (87/122)\u001b[K\rremote: Counting objects:  72% (88/122)\u001b[K\rremote: Counting objects:  73% (90/122)\u001b[K\rremote: Counting objects:  74% (91/122)\u001b[K\rremote: Counting objects:  75% (92/122)\u001b[K\rremote: Counting objects:  76% (93/122)\u001b[K\rremote: Counting objects:  77% (94/122)\u001b[K\rremote: Counting objects:  78% (96/122)\u001b[K\rremote: Counting objects:  79% (97/122)\u001b[K\rremote: Counting objects:  80% (98/122)\u001b[K\rremote: Counting objects:  81% (99/122)\u001b[K\rremote: Counting objects:  82% (101/122)\u001b[K\rremote: Counting objects:  83% (102/122)\u001b[K\rremote: Counting objects:  84% (103/122)\u001b[K\rremote: Counting objects:  85% (104/122)\u001b[K\rremote: Counting objects:  86% (105/122)\u001b[K\rremote: Counting objects:  87% (107/122)\u001b[K\rremote: Counting objects:  88% (108/122)\u001b[K\rremote: Counting objects:  89% (109/122)\u001b[K\rremote: Counting objects:  90% (110/122)\u001b[K\rremote: Counting objects:  91% (112/122)\u001b[K\rremote: Counting objects:  92% (113/122)\u001b[K\rremote: Counting objects:  93% (114/122)\u001b[K\rremote: Counting objects:  94% (115/122)\u001b[K\rremote: Counting objects:  95% (116/122)\u001b[K\rremote: Counting objects:  96% (118/122)\u001b[K\rremote: Counting objects:  97% (119/122)\u001b[K\rremote: Counting objects:  98% (120/122)\u001b[K\rremote: Counting objects:  99% (121/122)\u001b[K\rremote: Counting objects: 100% (122/122)\u001b[K\rremote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/77)\u001b[K\rremote: Compressing objects:   2% (2/77)\u001b[K\rremote: Compressing objects:   3% (3/77)\u001b[K\rremote: Compressing objects:   5% (4/77)\u001b[K\rremote: Compressing objects:   6% (5/77)\u001b[K\rremote: Compressing objects:   7% (6/77)\u001b[K\rremote: Compressing objects:   9% (7/77)\u001b[K\rremote: Compressing objects:  10% (8/77)\u001b[K\rremote: Compressing objects:  11% (9/77)\u001b[K\rremote: Compressing objects:  12% (10/77)\u001b[K\rremote: Compressing objects:  14% (11/77)\u001b[K\rremote: Compressing objects:  15% (12/77)\u001b[K\rremote: Compressing objects:  16% (13/77)\u001b[K\rremote: Compressing objects:  18% (14/77)\u001b[K\rremote: Compressing objects:  19% (15/77)\u001b[K\rremote: Compressing objects:  20% (16/77)\u001b[K\rremote: Compressing objects:  22% (17/77)\u001b[K\rremote: Compressing objects:  23% (18/77)\u001b[K\rremote: Compressing objects:  24% (19/77)\u001b[K\rremote: Compressing objects:  25% (20/77)\u001b[K\rremote: Compressing objects:  27% (21/77)\u001b[K\rremote: Compressing objects:  28% (22/77)\u001b[K\rremote: Compressing objects:  29% (23/77)\u001b[K\rremote: Compressing objects:  31% (24/77)\u001b[K\rremote: Compressing objects:  32% (25/77)\u001b[K\rremote: Compressing objects:  33% (26/77)\u001b[K\rremote: Compressing objects:  35% (27/77)\u001b[K\rremote: Compressing objects:  36% (28/77)\u001b[K\rremote: Compressing objects:  37% (29/77)\u001b[K\rremote: Compressing objects:  38% (30/77)\u001b[K\rremote: Compressing objects:  40% (31/77)\u001b[K\rremote: Compressing objects:  41% (32/77)\u001b[K\rremote: Compressing objects:  42% (33/77)\u001b[K\rremote: Compressing objects:  44% (34/77)\u001b[K\rremote: Compressing objects:  45% (35/77)\u001b[K\rremote: Compressing objects:  46% (36/77)\u001b[K\rremote: Compressing objects:  48% (37/77)\u001b[K\rremote: Compressing objects:  49% (38/77)\u001b[K\rremote: Compressing objects:  50% (39/77)\u001b[K\rremote: Compressing objects:  51% (40/77)\u001b[K\rremote: Compressing objects:  53% (41/77)\u001b[K\rremote: Compressing objects:  54% (42/77)\u001b[K\rremote: Compressing objects:  55% (43/77)\u001b[K\rremote: Compressing objects:  57% (44/77)\u001b[K\rremote: Compressing objects:  58% (45/77)\u001b[K\rremote: Compressing objects:  59% (46/77)\u001b[K\rremote: Compressing objects:  61% (47/77)\u001b[K\rremote: Compressing objects:  62% (48/77)\u001b[K\rremote: Compressing objects:  63% (49/77)\u001b[K\rremote: Compressing objects:  64% (50/77)\u001b[K\rremote: Compressing objects:  66% (51/77)\u001b[K\rremote: Compressing objects:  67% (52/77)\u001b[K\rremote: Compressing objects:  68% (53/77)\u001b[K\rremote: Compressing objects:  70% (54/77)\u001b[K\rremote: Compressing objects:  71% (55/77)\u001b[K\rremote: Compressing objects:  72% (56/77)\u001b[K\rremote: Compressing objects:  74% (57/77)\u001b[K\rremote: Compressing objects:  75% (58/77)\u001b[K\rremote: Compressing objects:  76% (59/77)\u001b[K\rremote: Compressing objects:  77% (60/77)\u001b[K\rremote: Compressing objects:  79% (61/77)\u001b[K\rremote: Compressing objects:  80% (62/77)\u001b[K\rremote: Compressing objects:  81% (63/77)\u001b[K\rremote: Compressing objects:  83% (64/77)\u001b[K\rremote: Compressing objects:  84% (65/77)\u001b[K\rremote: Compressing objects:  85% (66/77)\u001b[K\rremote: Compressing objects:  87% (67/77)\u001b[K\rremote: Compressing objects:  88% (68/77)\u001b[K\rremote: Compressing objects:  89% (69/77)\u001b[K\rremote: Compressing objects:  90% (70/77)\u001b[K\rremote: Compressing objects:  92% (71/77)\u001b[K\rremote: Compressing objects:  93% (72/77)\u001b[K\rremote: Compressing objects:  94% (73/77)\u001b[K\rremote: Compressing objects:  96% (74/77)\u001b[K\rremote: Compressing objects:  97% (75/77)\u001b[K\rremote: Compressing objects:  98% (76/77)\u001b[K\rremote: Compressing objects: 100% (77/77)\u001b[K\rremote: Compressing objects: 100% (77/77), done.\u001b[K\n",
            "Receiving objects:   0% (1/3653)   \rReceiving objects:   1% (37/3653)   \rReceiving objects:   2% (74/3653)   \rReceiving objects:   3% (110/3653)   \rReceiving objects:   4% (147/3653)   \rReceiving objects:   5% (183/3653)   \rReceiving objects:   6% (220/3653)   \rReceiving objects:   7% (256/3653)   \rReceiving objects:   8% (293/3653)   \rReceiving objects:   9% (329/3653)   \rReceiving objects:  10% (366/3653)   \rReceiving objects:  11% (402/3653)   \rReceiving objects:  12% (439/3653)   \rReceiving objects:  13% (475/3653)   \rReceiving objects:  14% (512/3653)   \rReceiving objects:  15% (548/3653)   \rReceiving objects:  16% (585/3653)   \rReceiving objects:  17% (622/3653)   \rReceiving objects:  18% (658/3653)   \rReceiving objects:  19% (695/3653)   \rReceiving objects:  20% (731/3653)   \rReceiving objects:  21% (768/3653)   \rReceiving objects:  22% (804/3653)   \rReceiving objects:  23% (841/3653)   \rReceiving objects:  24% (877/3653)   \rReceiving objects:  25% (914/3653)   \rReceiving objects:  26% (950/3653)   \rReceiving objects:  27% (987/3653)   \rReceiving objects:  28% (1023/3653)   \rReceiving objects:  29% (1060/3653)   \rReceiving objects:  30% (1096/3653)   \rReceiving objects:  31% (1133/3653)   \rReceiving objects:  32% (1169/3653)   \rReceiving objects:  33% (1206/3653)   \rReceiving objects:  34% (1243/3653)   \rReceiving objects:  35% (1279/3653)   \rReceiving objects:  36% (1316/3653)   \rReceiving objects:  37% (1352/3653)   \rReceiving objects:  38% (1389/3653)   \rReceiving objects:  39% (1425/3653)   \rReceiving objects:  40% (1462/3653)   \rReceiving objects:  41% (1498/3653)   \rReceiving objects:  42% (1535/3653)   \rReceiving objects:  43% (1571/3653)   \rReceiving objects:  44% (1608/3653)   \rReceiving objects:  45% (1644/3653)   \rReceiving objects:  46% (1681/3653)   \rReceiving objects:  47% (1717/3653)   \rReceiving objects:  48% (1754/3653)   \rReceiving objects:  49% (1790/3653)   \rReceiving objects:  50% (1827/3653)   \rReceiving objects:  51% (1864/3653)   \rReceiving objects:  52% (1900/3653)   \rReceiving objects:  53% (1937/3653)   \rReceiving objects:  54% (1973/3653)   \rReceiving objects:  55% (2010/3653)   \rReceiving objects:  56% (2046/3653)   \rReceiving objects:  57% (2083/3653)   \rReceiving objects:  58% (2119/3653)   \rReceiving objects:  59% (2156/3653)   \rReceiving objects:  60% (2192/3653)   \rReceiving objects:  61% (2229/3653)   \rReceiving objects:  62% (2265/3653)   \rReceiving objects:  63% (2302/3653)   \rReceiving objects:  64% (2338/3653)   \rReceiving objects:  65% (2375/3653)   \rReceiving objects:  66% (2411/3653)   \rReceiving objects:  67% (2448/3653)   \rReceiving objects:  68% (2485/3653)   \rReceiving objects:  69% (2521/3653)   \rReceiving objects:  70% (2558/3653)   \rReceiving objects:  71% (2594/3653)   \rReceiving objects:  72% (2631/3653)   \rReceiving objects:  73% (2667/3653)   \rReceiving objects:  74% (2704/3653)   \rReceiving objects:  75% (2740/3653)   \rReceiving objects:  76% (2777/3653)   \rReceiving objects:  77% (2813/3653)   \rReceiving objects:  78% (2850/3653)   \rReceiving objects:  79% (2886/3653)   \rReceiving objects:  80% (2923/3653)   \rReceiving objects:  81% (2959/3653)   \rReceiving objects:  82% (2996/3653)   \rReceiving objects:  83% (3032/3653)   \rReceiving objects:  84% (3069/3653)   \rReceiving objects:  85% (3106/3653)   \rReceiving objects:  86% (3142/3653)   \rReceiving objects:  87% (3179/3653)   \rReceiving objects:  88% (3215/3653)   \rReceiving objects:  89% (3252/3653)   \rReceiving objects:  90% (3288/3653)   \rReceiving objects:  91% (3325/3653)   \rReceiving objects:  92% (3361/3653)   \rReceiving objects:  93% (3398/3653)   \rReceiving objects:  94% (3434/3653)   \rReceiving objects:  95% (3471/3653)   \rReceiving objects:  96% (3507/3653)   \rReceiving objects:  97% (3544/3653)   \rReceiving objects:  98% (3580/3653)   \rremote: Total 3653 (delta 53), reused 67 (delta 27), pack-reused 3531\u001b[K\n",
            "Receiving objects:  99% (3617/3653)   \rReceiving objects: 100% (3653/3653)   \rReceiving objects: 100% (3653/3653), 8.16 MiB | 29.74 MiB/s, done.\n",
            "Resolving deltas:   0% (0/2277)   \rResolving deltas:   1% (25/2277)   \rResolving deltas:   2% (49/2277)   \rResolving deltas:   3% (71/2277)   \rResolving deltas:   4% (94/2277)   \rResolving deltas:   5% (114/2277)   \rResolving deltas:   6% (143/2277)   \rResolving deltas:   7% (160/2277)   \rResolving deltas:   8% (183/2277)   \rResolving deltas:   9% (206/2277)   \rResolving deltas:  10% (242/2277)   \rResolving deltas:  11% (266/2277)   \rResolving deltas:  12% (275/2277)   \rResolving deltas:  13% (298/2277)   \rResolving deltas:  14% (341/2277)   \rResolving deltas:  15% (342/2277)   \rResolving deltas:  16% (369/2277)   \rResolving deltas:  17% (388/2277)   \rResolving deltas:  18% (418/2277)   \rResolving deltas:  19% (436/2277)   \rResolving deltas:  20% (457/2277)   \rResolving deltas:  21% (493/2277)   \rResolving deltas:  22% (501/2277)   \rResolving deltas:  23% (524/2277)   \rResolving deltas:  24% (548/2277)   \rResolving deltas:  25% (573/2277)   \rResolving deltas:  26% (593/2277)   \rResolving deltas:  28% (643/2277)   \rResolving deltas:  29% (662/2277)   \rResolving deltas:  30% (684/2277)   \rResolving deltas:  31% (718/2277)   \rResolving deltas:  32% (739/2277)   \rResolving deltas:  34% (789/2277)   \rResolving deltas:  35% (811/2277)   \rResolving deltas:  36% (822/2277)   \rResolving deltas:  37% (855/2277)   \rResolving deltas:  38% (866/2277)   \rResolving deltas:  40% (918/2277)   \rResolving deltas:  41% (953/2277)   \rResolving deltas:  43% (992/2277)   \rResolving deltas:  44% (1004/2277)   \rResolving deltas:  45% (1039/2277)   \rResolving deltas:  46% (1056/2277)   \rResolving deltas:  49% (1118/2277)   \rResolving deltas:  52% (1189/2277)   \rResolving deltas:  53% (1228/2277)   \rResolving deltas:  55% (1255/2277)   \rResolving deltas:  57% (1306/2277)   \rResolving deltas:  61% (1407/2277)   \rResolving deltas:  65% (1483/2277)   \rResolving deltas:  66% (1523/2277)   \rResolving deltas:  67% (1531/2277)   \rResolving deltas:  68% (1555/2277)   \rResolving deltas:  70% (1601/2277)   \rResolving deltas:  72% (1652/2277)   \rResolving deltas:  76% (1747/2277)   \rResolving deltas:  78% (1797/2277)   \rResolving deltas:  79% (1799/2277)   \rResolving deltas:  80% (1822/2277)   \rResolving deltas:  81% (1846/2277)   \rResolving deltas:  82% (1873/2277)   \rResolving deltas:  83% (1890/2277)   \rResolving deltas:  84% (1913/2277)   \rResolving deltas:  85% (1955/2277)   \rResolving deltas:  86% (1960/2277)   \rResolving deltas:  88% (2011/2277)   \rResolving deltas:  89% (2032/2277)   \rResolving deltas:  90% (2065/2277)   \rResolving deltas:  91% (2079/2277)   \rResolving deltas:  92% (2109/2277)   \rResolving deltas:  93% (2119/2277)   \rResolving deltas:  94% (2143/2277)   \rResolving deltas:  95% (2166/2277)   \rResolving deltas:  96% (2198/2277)   \rResolving deltas:  97% (2211/2277)   \rResolving deltas:  98% (2247/2277)   \rResolving deltas:  99% (2255/2277)   \rResolving deltas: 100% (2277/2277)   \rResolving deltas: 100% (2277/2277), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e98xhZihX6yE",
        "colab_type": "code",
        "outputId": "607bf25b-55c0-4c65-e39d-6e916e3bb661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "! cd fastText && pip install ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/fastText\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (2.4.3)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (42.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (1.17.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2861872 sha256=b09e9175074006b9c5f472cb12d8cd4e37f3152d5d26bc59b51a129aef24965e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oe1t4gcg/wheels/a1/9f/52/696ce6c5c46325e840c76614ee5051458c0df10306987e7443\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5f2y3kKxByw",
        "colab_type": "code",
        "outputId": "05b937e1-af01-4237-e3fa-336c7bd33a43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "! wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.hi.300.bin.gz\n",
        "! wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-22 04:25:18--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.hi.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4371554972 (4.1G) [application/octet-stream]\n",
            "Saving to: ‘cc.hi.300.bin.gz’\n",
            "\n",
            "cc.hi.300.bin.gz    100%[===================>]   4.07G  46.5MB/s    in 96s     \n",
            "\n",
            "2020-01-22 04:26:55 (43.5 MB/s) - ‘cc.hi.300.bin.gz’ saved [4371554972/4371554972]\n",
            "\n",
            "--2020-01-22 04:26:57--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.en.300.bin.gz’\n",
            "\n",
            "cc.en.300.bin.gz    100%[===================>]   4.19G  43.9MB/s    in 94s     \n",
            "\n",
            "2020-01-22 04:28:31 (45.7 MB/s) - ‘cc.en.300.bin.gz’ saved [4503593528/4503593528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFwtbIlQVeKo",
        "colab_type": "code",
        "outputId": "9fc850e2-1611-4771-9357-dda58c86c169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "!pip install faiss-gpu"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting faiss-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/8d/d630c7ec7ad93feed005994c9849843d33bed08cf621ffb74fe9f81a45e2/faiss_gpu-1.6.1-cp36-cp36m-manylinux2010_x86_64.whl (41.0MB)\n",
            "\u001b[K     |████████████████████████████████| 41.0MB 47kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from faiss-gpu) (1.17.5)\n",
            "Installing collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsefQltkJEr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gunzip cc.en.300.bin.gz\n",
        "!gunzip cc.hi.300.bin.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6UwwhUMK2gM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv cc.en.300.bin data/cc.en.300.bin\n",
        "!mv cc.hi.300.bin data/cc.hi.300.bin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWqaL0Q50iZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data/crosslingual\n",
        "!mkdir data/crosslingual/dictionaries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQga275sN6_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "d856a319-8436-401e-863b-76c32742b3d8"
      },
      "source": [
        "! wget  https://dl.fbaipublicfiles.com/arrival/dictionaries/en-hi.txt\n",
        "! wget  https://dl.fbaipublicfiles.com/arrival/dictionaries/en-hi.0-5000.txt\n",
        "! wget  https://dl.fbaipublicfiles.com/arrival/dictionaries/hi-en.0-5000.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-22 04:34:43--  https://dl.fbaipublicfiles.com/arrival/dictionaries/en-hi.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 930856 (909K) [text/x-c++]\n",
            "Saving to: ‘en-hi.txt.1’\n",
            "\n",
            "en-hi.txt.1         100%[===================>] 909.04K   864KB/s    in 1.1s    \n",
            "\n",
            "2020-01-22 04:34:45 (864 KB/s) - ‘en-hi.txt.1’ saved [930856/930856]\n",
            "\n",
            "--2020-01-22 04:34:46--  https://dl.fbaipublicfiles.com/arrival/dictionaries/en-hi.0-5000.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 219327 (214K) [text/x-c++]\n",
            "Saving to: ‘en-hi.0-5000.txt’\n",
            "\n",
            "en-hi.0-5000.txt    100%[===================>] 214.19K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-01-22 04:34:47 (2.14 MB/s) - ‘en-hi.0-5000.txt’ saved [219327/219327]\n",
            "\n",
            "--2020-01-22 04:34:49--  https://dl.fbaipublicfiles.com/arrival/dictionaries/hi-en.0-5000.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 199063 (194K) [text/plain]\n",
            "Saving to: ‘hi-en.0-5000.txt’\n",
            "\n",
            "hi-en.0-5000.txt    100%[===================>] 194.40K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-01-22 04:34:50 (2.45 MB/s) - ‘hi-en.0-5000.txt’ saved [199063/199063]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUhn-XPlMVYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mv en-hi.txt data/crosslingual/dictionaries/en-hi.txt\n",
        "! mv en-hi.0-5000.txt data/crosslingual/dictionaries/en-hi.0-5000.txt\n",
        "! mv hi-en.0-5000.txt data/crosslingual/dictionaries/hi-en.0-5000.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HksZ8AhP3mM",
        "colab_type": "code",
        "outputId": "57c7ca55-cc7b-4932-c805-041b4448f405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! python supervised.py --src_lang hi --tgt_lang en --src_emb /content/data/cc.hi.300.bin --tgt_emb /content/data/cc.en.300.bin  --dico_train default"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 01/22/20 04:35:49 - 0:00:00 - ============ Initialized logger ============\n",
            "INFO - 01/22/20 04:35:49 - 0:00:00 - cuda: True\n",
            "                                     dico_build: S2T&T2S\n",
            "                                     dico_eval: default\n",
            "                                     dico_max_rank: 10000\n",
            "                                     dico_max_size: 0\n",
            "                                     dico_method: csls_knn_10\n",
            "                                     dico_min_size: 0\n",
            "                                     dico_threshold: 0\n",
            "                                     dico_train: default\n",
            "                                     emb_dim: 300\n",
            "                                     exp_id: \n",
            "                                     exp_name: debug\n",
            "                                     exp_path: /content/dumped/debug/co4q30tuhy\n",
            "                                     export: txt\n",
            "                                     max_vocab: 200000\n",
            "                                     n_refinement: 5\n",
            "                                     normalize_embeddings: \n",
            "                                     seed: -1\n",
            "                                     src_emb: /content/data/cc.hi.300.bin\n",
            "                                     src_lang: hi\n",
            "                                     tgt_emb: /content/data/cc.en.300.bin\n",
            "                                     tgt_lang: en\n",
            "                                     verbose: 2\n",
            "INFO - 01/22/20 04:35:49 - 0:00:00 - The experiment will be stored in /content/dumped/debug/co4q30tuhy\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "INFO - 01/22/20 04:35:49 - 0:00:00 - ============ Initialized logger ============\n",
            "INFO - 01/22/20 04:35:49 - 0:00:00 - cuda: True\n",
            "                                     dico_build: S2T&T2S\n",
            "                                     dico_eval: default\n",
            "                                     dico_max_rank: 10000\n",
            "                                     dico_max_size: 0\n",
            "                                     dico_method: csls_knn_10\n",
            "                                     dico_min_size: 0\n",
            "                                     dico_threshold: 0\n",
            "                                     dico_train: default\n",
            "                                     emb_dim: 300\n",
            "                                     exp_id: \n",
            "                                     exp_name: debug\n",
            "                                     exp_path: /content/dumped/debug/co4q30tuhy\n",
            "                                     export: txt\n",
            "                                     max_vocab: 200000\n",
            "                                     n_refinement: 5\n",
            "                                     normalize_embeddings: \n",
            "                                     seed: -1\n",
            "                                     src_emb: /content/data/cc.hi.300.bin\n",
            "                                     src_lang: hi\n",
            "                                     tgt_emb: /content/data/cc.en.300.bin\n",
            "                                     tgt_lang: en\n",
            "                                     verbose: 2\n",
            "INFO - 01/22/20 04:35:49 - 0:00:00 - The experiment will be stored in /content/dumped/debug/co4q30tuhy\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "tcmalloc: large alloc 4651999232 bytes == 0x16cc0000 @  0x7f8a3498b887 0x7f89c33ca363 0x7f89c33ba3df 0x7f89c33ba9f1 0x7f89c33899b3 0x7f89c33add20 0x5674fc 0x50abb3 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390\n",
            "tcmalloc: large alloc 4651999232 bytes == 0x16cc0000 @  0x7f8a3498b887 0x7f89c33ca363 0x7f89c33ba3df 0x7f89c33ba9f1 0x7f89c33899b3 0x7f89c33add20 0x5674fc 0x50abb3 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390\n",
            "tcmalloc: large alloc 2252005376 bytes == 0x12c13e000 @  0x7f8a3498b887 0x7f89c33ca363 0x7f89c33ba42e 0x7f89c33ba9f1 0x7f89c33899b3 0x7f89c33add20 0x5674fc 0x50abb3 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390\n",
            "tcmalloc: large alloc 2252005376 bytes == 0x12c13e000 @  0x7f8a3498b887 0x7f89c33ca363 0x7f89c33ba42e 0x7f89c33ba9f1 0x7f89c33899b3 0x7f89c33add20 0x5674fc 0x50abb3 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390\n",
            "INFO - 01/22/20 04:36:03 - 0:00:15 - Loaded binary model. Generating embeddings ...\n",
            "INFO - 01/22/20 04:36:03 - 0:00:15 - Loaded binary model. Generating embeddings ...\n",
            "tcmalloc: large alloc 2252005376 bytes == 0x7f88b98e8000 @  0x7f8a349891e7 0x7f8a31f94f71 0x7f8a31ff855d 0x7f8a31ff8733 0x7f8a32096768 0x7f8a32096fc4 0x7f8a32097112 0x5678b3 0x5a067e 0x7f8a31fe406d 0x50a8af 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50b403 0x635222 0x6352d7\n",
            "tcmalloc: large alloc 2252005376 bytes == 0x7f88b98e8000 @  0x7f8a349891e7 0x7f8a31f94f71 0x7f8a31ff855d 0x7f8a31ff8733 0x7f8a32096768 0x7f8a32096fc4 0x7f8a32097112 0x5678b3 0x5a067e 0x7f8a31fe406d 0x50a8af 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50b403 0x635222 0x6352d7\n",
            "INFO - 01/22/20 04:36:42 - 0:00:53 - Generated embeddings for 1876665 words.\n",
            "INFO - 01/22/20 04:36:42 - 0:00:53 - Generated embeddings for 1876665 words.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "tcmalloc: large alloc 4800004096 bytes == 0xcd2a000 @  0x7f8a3498b887 0x7f89c33ca363 0x7f89c33ba3df 0x7f89c33ba9f1 0x7f89c33899b3 0x7f89c33add20 0x5674fc 0x50abb3 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390\n",
            "tcmalloc: large alloc 4800004096 bytes == 0xcd2a000 @  0x7f8a3498b887 0x7f89c33ca363 0x7f89c33ba3df 0x7f89c33ba9f1 0x7f89c33899b3 0x7f89c33add20 0x5674fc 0x50abb3 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390\n",
            "tcmalloc: large alloc 2400002048 bytes == 0x7f882a816000 @  0x7f8a3498b887 0x7f89c33ca363 0x7f89c33ba42e 0x7f89c33ba9f1 0x7f89c33899b3 0x7f89c33add20 0x5674fc 0x50abb3 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390\n",
            "tcmalloc: large alloc 2400002048 bytes == 0x7f882a816000 @  0x7f8a3498b887 0x7f89c33ca363 0x7f89c33ba42e 0x7f89c33ba9f1 0x7f89c33899b3 0x7f89c33add20 0x5674fc 0x50abb3 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390\n",
            "INFO - 01/22/20 04:40:07 - 0:04:18 - Loaded binary model. Generating embeddings ...\n",
            "INFO - 01/22/20 04:40:07 - 0:04:18 - Loaded binary model. Generating embeddings ...\n",
            "tcmalloc: large alloc 2400002048 bytes == 0x7f879ac84000 @  0x7f8a349891e7 0x7f8a31f94f71 0x7f8a31ff855d 0x7f8a31ff8733 0x7f8a32096768 0x7f8a32096fc4 0x7f8a32097112 0x5678b3 0x5a067e 0x7f8a31fe406d 0x50a8af 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50b403 0x635222 0x6352d7\n",
            "tcmalloc: large alloc 2400002048 bytes == 0x7f879ac84000 @  0x7f8a349891e7 0x7f8a31f94f71 0x7f8a31ff855d 0x7f8a31ff8733 0x7f8a32096768 0x7f8a32096fc4 0x7f8a32097112 0x5678b3 0x5a067e 0x7f8a31fe406d 0x50a8af 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50b403 0x635222 0x6352d7\n",
            "INFO - 01/22/20 04:40:42 - 0:04:54 - Generated embeddings for 2000000 words.\n",
            "INFO - 01/22/20 04:40:42 - 0:04:54 - Generated embeddings for 2000000 words.\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:40:53 - 0:05:04 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:40:53 - 0:05:04 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:40:53 - 0:05:04 - Validation metric: precision_at_1-csls_knn_10\n",
            "INFO - 01/22/20 04:40:53 - 0:05:04 - Starting iteration 0...\n",
            "INFO - 01/22/20 04:40:53 - 0:05:04 - Validation metric: precision_at_1-csls_knn_10\n",
            "INFO - 01/22/20 04:40:53 - 0:05:04 - Starting iteration 0...\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:40:54 - 0:05:05 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:40:54 - 0:05:05 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:40:54 - 0:05:05 - 4886 source words - nn - Precision at k = 1: 71.899304\n",
            "INFO - 01/22/20 04:40:54 - 0:05:05 - 4886 source words - nn - Precision at k = 5: 86.123619\n",
            "INFO - 01/22/20 04:40:54 - 0:05:05 - 4886 source words - nn - Precision at k = 10: 89.521081\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:40:54 - 0:05:05 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:40:54 - 0:05:05 - 4886 source words - nn - Precision at k = 1: 71.899304\n",
            "INFO - 01/22/20 04:40:54 - 0:05:05 - 4886 source words - nn - Precision at k = 5: 86.123619\n",
            "INFO - 01/22/20 04:40:54 - 0:05:05 - 4886 source words - nn - Precision at k = 10: 89.521081\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:40:54 - 0:05:05 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:42:01 - 0:06:12 - 4886 source words - csls_knn_10 - Precision at k = 1: 71.796971\n",
            "INFO - 01/22/20 04:42:01 - 0:06:12 - 4886 source words - csls_knn_10 - Precision at k = 5: 85.386819\n",
            "INFO - 01/22/20 04:42:01 - 0:06:12 - 4886 source words - csls_knn_10 - Precision at k = 10: 88.927548\n",
            "INFO - 01/22/20 04:42:01 - 0:06:12 - 4886 source words - csls_knn_10 - Precision at k = 1: 71.796971\n",
            "INFO - 01/22/20 04:42:01 - 0:06:12 - 4886 source words - csls_knn_10 - Precision at k = 5: 85.386819\n",
            "INFO - 01/22/20 04:42:01 - 0:06:12 - 4886 source words - csls_knn_10 - Precision at k = 10: 88.927548\n",
            "INFO - 01/22/20 04:42:04 - 0:06:15 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:42:04 - 0:06:15 - New train dictionary of 6261 pairs.\n",
            "INFO - 01/22/20 04:42:04 - 0:06:15 - Mean cosine (nn method, S2T build, 10000 max size): 0.50284\n",
            "INFO - 01/22/20 04:42:04 - 0:06:15 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:42:04 - 0:06:15 - New train dictionary of 6261 pairs.\n",
            "INFO - 01/22/20 04:42:04 - 0:06:15 - Mean cosine (nn method, S2T build, 10000 max size): 0.50284\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - New train dictionary of 5032 pairs.\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.52626\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - __log__:{\"n_iter\": 0, \"precision_at_1-nn\": 71.89930413426116, \"precision_at_5-nn\": 86.123618501842, \"precision_at_10-nn\": 89.52108063855914, \"precision_at_1-csls_knn_10\": 71.79697093737208, \"precision_at_5-csls_knn_10\": 85.38681948424069, \"precision_at_10-csls_knn_10\": 88.92754809660254, \"mean_cosine-nn-S2T-10000\": 0.5028404593467712, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5262638330459595}\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - * Best value for \"precision_at_1-csls_knn_10\": 71.79697\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - * Saving the mapping to /content/dumped/debug/co4q30tuhy/best_mapping.pth ...\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - End of iteration 0.\n",
            "                                     \n",
            "                                     \n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - Starting iteration 1...\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - New train dictionary of 5032 pairs.\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.52626\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - __log__:{\"n_iter\": 0, \"precision_at_1-nn\": 71.89930413426116, \"precision_at_5-nn\": 86.123618501842, \"precision_at_10-nn\": 89.52108063855914, \"precision_at_1-csls_knn_10\": 71.79697093737208, \"precision_at_5-csls_knn_10\": 85.38681948424069, \"precision_at_10-csls_knn_10\": 88.92754809660254, \"mean_cosine-nn-S2T-10000\": 0.5028404593467712, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5262638330459595}\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - * Best value for \"precision_at_1-csls_knn_10\": 71.79697\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - * Saving the mapping to /content/dumped/debug/co4q30tuhy/best_mapping.pth ...\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - End of iteration 0.\n",
            "                                     \n",
            "                                     \n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - Starting iteration 1...\n",
            "INFO - 01/22/20 04:42:22 - 0:06:34 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:42:40 - 0:06:51 - New train dictionary of 2829 pairs.\n",
            "INFO - 01/22/20 04:42:40 - 0:06:51 - New train dictionary of 2829 pairs.\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:42:40 - 0:06:52 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:42:40 - 0:06:52 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:42:41 - 0:06:52 - 4886 source words - nn - Precision at k = 1: 60.069587\n",
            "INFO - 01/22/20 04:42:41 - 0:06:52 - 4886 source words - nn - Precision at k = 5: 75.644699\n",
            "INFO - 01/22/20 04:42:41 - 0:06:52 - 4886 source words - nn - Precision at k = 10: 79.819894\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:42:41 - 0:06:52 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:42:41 - 0:06:52 - 4886 source words - nn - Precision at k = 1: 60.069587\n",
            "INFO - 01/22/20 04:42:41 - 0:06:52 - 4886 source words - nn - Precision at k = 5: 75.644699\n",
            "INFO - 01/22/20 04:42:41 - 0:06:52 - 4886 source words - nn - Precision at k = 10: 79.819894\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:42:41 - 0:06:52 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:42:49 - 0:07:00 - 4886 source words - csls_knn_10 - Precision at k = 1: 59.967253\n",
            "INFO - 01/22/20 04:42:49 - 0:07:00 - 4886 source words - csls_knn_10 - Precision at k = 5: 73.536635\n",
            "INFO - 01/22/20 04:42:49 - 0:07:00 - 4886 source words - csls_knn_10 - Precision at k = 10: 77.629963\n",
            "INFO - 01/22/20 04:42:49 - 0:07:00 - 4886 source words - csls_knn_10 - Precision at k = 1: 59.967253\n",
            "INFO - 01/22/20 04:42:49 - 0:07:00 - 4886 source words - csls_knn_10 - Precision at k = 5: 73.536635\n",
            "INFO - 01/22/20 04:42:49 - 0:07:00 - 4886 source words - csls_knn_10 - Precision at k = 10: 77.629963\n",
            "INFO - 01/22/20 04:42:51 - 0:07:03 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:42:51 - 0:07:03 - New train dictionary of 6799 pairs.\n",
            "INFO - 01/22/20 04:42:51 - 0:07:03 - Mean cosine (nn method, S2T build, 10000 max size): 0.51934\n",
            "INFO - 01/22/20 04:42:51 - 0:07:03 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:42:51 - 0:07:03 - New train dictionary of 6799 pairs.\n",
            "INFO - 01/22/20 04:42:51 - 0:07:03 - Mean cosine (nn method, S2T build, 10000 max size): 0.51934\n",
            "INFO - 01/22/20 04:43:10 - 0:07:22 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:43:10 - 0:07:22 - New train dictionary of 5330 pairs.\n",
            "INFO - 01/22/20 04:43:10 - 0:07:22 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.55000\n",
            "INFO - 01/22/20 04:43:10 - 0:07:22 - __log__:{\"n_iter\": 1, \"precision_at_1-nn\": 60.06958657388457, \"precision_at_5-nn\": 75.64469914040114, \"precision_at_10-nn\": 79.81989357347523, \"precision_at_1-csls_knn_10\": 59.9672533769955, \"precision_at_5-csls_knn_10\": 73.53663528448628, \"precision_at_10-csls_knn_10\": 77.62996316004912, \"mean_cosine-nn-S2T-10000\": 0.5193426609039307, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5499966740608215}\n",
            "INFO - 01/22/20 04:43:10 - 0:07:22 - End of iteration 1.\n",
            "                                     \n",
            "                                     \n",
            "INFO - 01/22/20 04:43:10 - 0:07:22 - Starting iteration 2...\n",
            "INFO - 01/22/20 04:43:10 - 0:07:22 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:43:10 - 0:07:22 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:43:10 - 0:07:22 - New train dictionary of 5330 pairs.\n",
            "INFO - 01/22/20 04:43:10 - 0:07:22 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.55000\n",
            "INFO - 01/22/20 04:43:10 - 0:07:22 - __log__:{\"n_iter\": 1, \"precision_at_1-nn\": 60.06958657388457, \"precision_at_5-nn\": 75.64469914040114, \"precision_at_10-nn\": 79.81989357347523, \"precision_at_1-csls_knn_10\": 59.9672533769955, \"precision_at_5-csls_knn_10\": 73.53663528448628, \"precision_at_10-csls_knn_10\": 77.62996316004912, \"mean_cosine-nn-S2T-10000\": 0.5193426609039307, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5499966740608215}\n",
            "INFO - 01/22/20 04:43:10 - 0:07:22 - End of iteration 1.\n",
            "                                     \n",
            "                                     \n",
            "INFO - 01/22/20 04:43:10 - 0:07:22 - Starting iteration 2...\n",
            "INFO - 01/22/20 04:43:10 - 0:07:22 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:43:28 - 0:07:39 - New train dictionary of 3022 pairs.\n",
            "INFO - 01/22/20 04:43:28 - 0:07:39 - New train dictionary of 3022 pairs.\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:43:28 - 0:07:40 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:43:28 - 0:07:40 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:43:29 - 0:07:40 - 4886 source words - nn - Precision at k = 1: 58.984855\n",
            "INFO - 01/22/20 04:43:29 - 0:07:40 - 4886 source words - nn - Precision at k = 5: 74.212034\n",
            "INFO - 01/22/20 04:43:29 - 0:07:40 - 4886 source words - nn - Precision at k = 10: 78.428162\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:43:29 - 0:07:40 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:43:29 - 0:07:40 - 4886 source words - nn - Precision at k = 1: 58.984855\n",
            "INFO - 01/22/20 04:43:29 - 0:07:40 - 4886 source words - nn - Precision at k = 5: 74.212034\n",
            "INFO - 01/22/20 04:43:29 - 0:07:40 - 4886 source words - nn - Precision at k = 10: 78.428162\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:43:29 - 0:07:40 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:43:37 - 0:07:48 - 4886 source words - csls_knn_10 - Precision at k = 1: 58.411789\n",
            "INFO - 01/22/20 04:43:37 - 0:07:48 - 4886 source words - csls_knn_10 - Precision at k = 5: 72.042571\n",
            "INFO - 01/22/20 04:43:37 - 0:07:48 - 4886 source words - csls_knn_10 - Precision at k = 10: 76.524765\n",
            "INFO - 01/22/20 04:43:37 - 0:07:48 - 4886 source words - csls_knn_10 - Precision at k = 1: 58.411789\n",
            "INFO - 01/22/20 04:43:37 - 0:07:48 - 4886 source words - csls_knn_10 - Precision at k = 5: 72.042571\n",
            "INFO - 01/22/20 04:43:37 - 0:07:48 - 4886 source words - csls_knn_10 - Precision at k = 10: 76.524765\n",
            "INFO - 01/22/20 04:43:39 - 0:07:50 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:43:39 - 0:07:50 - New train dictionary of 6883 pairs.\n",
            "INFO - 01/22/20 04:43:39 - 0:07:50 - Mean cosine (nn method, S2T build, 10000 max size): 0.51679\n",
            "INFO - 01/22/20 04:43:39 - 0:07:50 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:43:39 - 0:07:50 - New train dictionary of 6883 pairs.\n",
            "INFO - 01/22/20 04:43:39 - 0:07:50 - Mean cosine (nn method, S2T build, 10000 max size): 0.51679\n",
            "INFO - 01/22/20 04:43:58 - 0:08:09 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:43:58 - 0:08:09 - New train dictionary of 5319 pairs.\n",
            "INFO - 01/22/20 04:43:58 - 0:08:09 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.54893\n",
            "INFO - 01/22/20 04:43:58 - 0:08:09 - __log__:{\"n_iter\": 2, \"precision_at_1-nn\": 58.98485468686042, \"precision_at_5-nn\": 74.21203438395415, \"precision_at_10-nn\": 78.42816209578388, \"precision_at_1-csls_knn_10\": 58.411788784281626, \"precision_at_5-csls_knn_10\": 72.04257060990585, \"precision_at_10-csls_knn_10\": 76.52476463364715, \"mean_cosine-nn-S2T-10000\": 0.516790509223938, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5489301085472107}\n",
            "INFO - 01/22/20 04:43:58 - 0:08:09 - End of iteration 2.\n",
            "                                     \n",
            "                                     \n",
            "INFO - 01/22/20 04:43:58 - 0:08:09 - Starting iteration 3...\n",
            "INFO - 01/22/20 04:43:58 - 0:08:09 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:43:58 - 0:08:09 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:43:58 - 0:08:09 - New train dictionary of 5319 pairs.\n",
            "INFO - 01/22/20 04:43:58 - 0:08:09 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.54893\n",
            "INFO - 01/22/20 04:43:58 - 0:08:09 - __log__:{\"n_iter\": 2, \"precision_at_1-nn\": 58.98485468686042, \"precision_at_5-nn\": 74.21203438395415, \"precision_at_10-nn\": 78.42816209578388, \"precision_at_1-csls_knn_10\": 58.411788784281626, \"precision_at_5-csls_knn_10\": 72.04257060990585, \"precision_at_10-csls_knn_10\": 76.52476463364715, \"mean_cosine-nn-S2T-10000\": 0.516790509223938, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5489301085472107}\n",
            "INFO - 01/22/20 04:43:58 - 0:08:09 - End of iteration 2.\n",
            "                                     \n",
            "                                     \n",
            "INFO - 01/22/20 04:43:58 - 0:08:09 - Starting iteration 3...\n",
            "INFO - 01/22/20 04:43:58 - 0:08:09 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:44:16 - 0:08:27 - New train dictionary of 3079 pairs.\n",
            "INFO - 01/22/20 04:44:16 - 0:08:27 - New train dictionary of 3079 pairs.\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:44:16 - 0:08:27 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:44:16 - 0:08:27 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:44:17 - 0:08:28 - 4886 source words - nn - Precision at k = 1: 58.575522\n",
            "INFO - 01/22/20 04:44:17 - 0:08:28 - 4886 source words - nn - Precision at k = 5: 73.495702\n",
            "INFO - 01/22/20 04:44:17 - 0:08:28 - 4886 source words - nn - Precision at k = 10: 78.162096\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:44:17 - 0:08:28 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:44:17 - 0:08:28 - 4886 source words - nn - Precision at k = 1: 58.575522\n",
            "INFO - 01/22/20 04:44:17 - 0:08:28 - 4886 source words - nn - Precision at k = 5: 73.495702\n",
            "INFO - 01/22/20 04:44:17 - 0:08:28 - 4886 source words - nn - Precision at k = 10: 78.162096\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:44:17 - 0:08:28 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:44:24 - 0:08:36 - 4886 source words - csls_knn_10 - Precision at k = 1: 57.838723\n",
            "INFO - 01/22/20 04:44:24 - 0:08:36 - 4886 source words - csls_knn_10 - Precision at k = 5: 71.449038\n",
            "INFO - 01/22/20 04:44:24 - 0:08:36 - 4886 source words - csls_knn_10 - Precision at k = 10: 75.992632\n",
            "INFO - 01/22/20 04:44:24 - 0:08:36 - 4886 source words - csls_knn_10 - Precision at k = 1: 57.838723\n",
            "INFO - 01/22/20 04:44:24 - 0:08:36 - 4886 source words - csls_knn_10 - Precision at k = 5: 71.449038\n",
            "INFO - 01/22/20 04:44:24 - 0:08:36 - 4886 source words - csls_knn_10 - Precision at k = 10: 75.992632\n",
            "INFO - 01/22/20 04:44:27 - 0:08:38 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:44:27 - 0:08:38 - New train dictionary of 6864 pairs.\n",
            "INFO - 01/22/20 04:44:27 - 0:08:38 - Mean cosine (nn method, S2T build, 10000 max size): 0.51744\n",
            "INFO - 01/22/20 04:44:27 - 0:08:38 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:44:27 - 0:08:38 - New train dictionary of 6864 pairs.\n",
            "INFO - 01/22/20 04:44:27 - 0:08:38 - Mean cosine (nn method, S2T build, 10000 max size): 0.51744\n",
            "INFO - 01/22/20 04:44:46 - 0:08:57 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:44:46 - 0:08:57 - New train dictionary of 5291 pairs.\n",
            "INFO - 01/22/20 04:44:46 - 0:08:57 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.55002\n",
            "INFO - 01/22/20 04:44:46 - 0:08:57 - __log__:{\"n_iter\": 3, \"precision_at_1-nn\": 58.57552189930414, \"precision_at_5-nn\": 73.49570200573066, \"precision_at_10-nn\": 78.16209578387229, \"precision_at_1-csls_knn_10\": 57.83872288170282, \"precision_at_5-csls_knn_10\": 71.44903806794925, \"precision_at_10-csls_knn_10\": 75.99263200982399, \"mean_cosine-nn-S2T-10000\": 0.5174381732940674, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5500177145004272}\n",
            "INFO - 01/22/20 04:44:46 - 0:08:57 - End of iteration 3.\n",
            "                                     \n",
            "                                     \n",
            "INFO - 01/22/20 04:44:46 - 0:08:57 - Starting iteration 4...\n",
            "INFO - 01/22/20 04:44:46 - 0:08:57 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:44:46 - 0:08:57 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:44:46 - 0:08:57 - New train dictionary of 5291 pairs.\n",
            "INFO - 01/22/20 04:44:46 - 0:08:57 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.55002\n",
            "INFO - 01/22/20 04:44:46 - 0:08:57 - __log__:{\"n_iter\": 3, \"precision_at_1-nn\": 58.57552189930414, \"precision_at_5-nn\": 73.49570200573066, \"precision_at_10-nn\": 78.16209578387229, \"precision_at_1-csls_knn_10\": 57.83872288170282, \"precision_at_5-csls_knn_10\": 71.44903806794925, \"precision_at_10-csls_knn_10\": 75.99263200982399, \"mean_cosine-nn-S2T-10000\": 0.5174381732940674, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5500177145004272}\n",
            "INFO - 01/22/20 04:44:46 - 0:08:57 - End of iteration 3.\n",
            "                                     \n",
            "                                     \n",
            "INFO - 01/22/20 04:44:46 - 0:08:57 - Starting iteration 4...\n",
            "INFO - 01/22/20 04:44:46 - 0:08:57 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:45:04 - 0:09:15 - New train dictionary of 3110 pairs.\n",
            "INFO - 01/22/20 04:45:04 - 0:09:15 - New train dictionary of 3110 pairs.\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:45:04 - 0:09:15 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:45:04 - 0:09:15 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:45:04 - 0:09:16 - 4886 source words - nn - Precision at k = 1: 58.350389\n",
            "INFO - 01/22/20 04:45:04 - 0:09:16 - 4886 source words - nn - Precision at k = 5: 73.311502\n",
            "INFO - 01/22/20 04:45:04 - 0:09:16 - 4886 source words - nn - Precision at k = 10: 77.650430\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:45:04 - 0:09:16 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:45:04 - 0:09:16 - 4886 source words - nn - Precision at k = 1: 58.350389\n",
            "INFO - 01/22/20 04:45:04 - 0:09:16 - 4886 source words - nn - Precision at k = 5: 73.311502\n",
            "INFO - 01/22/20 04:45:04 - 0:09:16 - 4886 source words - nn - Precision at k = 10: 77.650430\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:45:04 - 0:09:16 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:45:12 - 0:09:24 - 4886 source words - csls_knn_10 - Precision at k = 1: 57.715923\n",
            "INFO - 01/22/20 04:45:12 - 0:09:24 - 4886 source words - csls_knn_10 - Precision at k = 5: 71.182972\n",
            "INFO - 01/22/20 04:45:12 - 0:09:24 - 4886 source words - csls_knn_10 - Precision at k = 10: 75.706099\n",
            "INFO - 01/22/20 04:45:12 - 0:09:24 - 4886 source words - csls_knn_10 - Precision at k = 1: 57.715923\n",
            "INFO - 01/22/20 04:45:12 - 0:09:24 - 4886 source words - csls_knn_10 - Precision at k = 5: 71.182972\n",
            "INFO - 01/22/20 04:45:12 - 0:09:24 - 4886 source words - csls_knn_10 - Precision at k = 10: 75.706099\n",
            "INFO - 01/22/20 04:45:15 - 0:09:26 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:45:15 - 0:09:26 - New train dictionary of 6895 pairs.\n",
            "INFO - 01/22/20 04:45:15 - 0:09:26 - Mean cosine (nn method, S2T build, 10000 max size): 0.51688\n",
            "INFO - 01/22/20 04:45:15 - 0:09:26 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:45:15 - 0:09:26 - New train dictionary of 6895 pairs.\n",
            "INFO - 01/22/20 04:45:15 - 0:09:26 - Mean cosine (nn method, S2T build, 10000 max size): 0.51688\n",
            "INFO - 01/22/20 04:45:34 - 0:09:45 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:45:34 - 0:09:45 - New train dictionary of 5331 pairs.\n",
            "INFO - 01/22/20 04:45:34 - 0:09:45 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.54939\n",
            "INFO - 01/22/20 04:45:34 - 0:09:45 - __log__:{\"n_iter\": 4, \"precision_at_1-nn\": 58.35038886614819, \"precision_at_5-nn\": 73.31150225133032, \"precision_at_10-nn\": 77.65042979942693, \"precision_at_1-csls_knn_10\": 57.715923045435936, \"precision_at_5-csls_knn_10\": 71.18297175603766, \"precision_at_10-csls_knn_10\": 75.70609905853459, \"mean_cosine-nn-S2T-10000\": 0.5168818235397339, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5493908524513245}\n",
            "INFO - 01/22/20 04:45:34 - 0:09:45 - End of iteration 4.\n",
            "                                     \n",
            "                                     \n",
            "INFO - 01/22/20 04:45:34 - 0:09:45 - Starting iteration 5...\n",
            "INFO - 01/22/20 04:45:34 - 0:09:45 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:45:34 - 0:09:45 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:45:34 - 0:09:45 - New train dictionary of 5331 pairs.\n",
            "INFO - 01/22/20 04:45:34 - 0:09:45 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.54939\n",
            "INFO - 01/22/20 04:45:34 - 0:09:45 - __log__:{\"n_iter\": 4, \"precision_at_1-nn\": 58.35038886614819, \"precision_at_5-nn\": 73.31150225133032, \"precision_at_10-nn\": 77.65042979942693, \"precision_at_1-csls_knn_10\": 57.715923045435936, \"precision_at_5-csls_knn_10\": 71.18297175603766, \"precision_at_10-csls_knn_10\": 75.70609905853459, \"mean_cosine-nn-S2T-10000\": 0.5168818235397339, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5493908524513245}\n",
            "INFO - 01/22/20 04:45:34 - 0:09:45 - End of iteration 4.\n",
            "                                     \n",
            "                                     \n",
            "INFO - 01/22/20 04:45:34 - 0:09:45 - Starting iteration 5...\n",
            "INFO - 01/22/20 04:45:34 - 0:09:45 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:45:51 - 0:10:03 - New train dictionary of 3122 pairs.\n",
            "INFO - 01/22/20 04:45:51 - 0:10:03 - New train dictionary of 3122 pairs.\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:45:52 - 0:10:03 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:45:52 - 0:10:03 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:45:52 - 0:10:03 - 4886 source words - nn - Precision at k = 1: 57.859190\n",
            "INFO - 01/22/20 04:45:52 - 0:10:03 - 4886 source words - nn - Precision at k = 5: 73.209169\n",
            "INFO - 01/22/20 04:45:52 - 0:10:03 - 4886 source words - nn - Precision at k = 10: 77.425297\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:45:52 - 0:10:03 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:45:52 - 0:10:03 - 4886 source words - nn - Precision at k = 1: 57.859190\n",
            "INFO - 01/22/20 04:45:52 - 0:10:03 - 4886 source words - nn - Precision at k = 5: 73.209169\n",
            "INFO - 01/22/20 04:45:52 - 0:10:03 - 4886 source words - nn - Precision at k = 10: 77.425297\n",
            "/content/src/evaluation/../../data/crosslingual/dictionaries/hi-en.0-5000.txt\n",
            "INFO - 01/22/20 04:45:52 - 0:10:03 - Found 7930 pairs of words in the dictionary (4886 unique). 71 other pairs contained at least one unknown word (20 in lang1, 71 in lang2)\n",
            "INFO - 01/22/20 04:46:00 - 0:10:11 - 4886 source words - csls_knn_10 - Precision at k = 1: 57.429390\n",
            "INFO - 01/22/20 04:46:00 - 0:10:11 - 4886 source words - csls_knn_10 - Precision at k = 5: 71.203438\n",
            "INFO - 01/22/20 04:46:00 - 0:10:11 - 4886 source words - csls_knn_10 - Precision at k = 10: 75.378633\n",
            "INFO - 01/22/20 04:46:00 - 0:10:11 - 4886 source words - csls_knn_10 - Precision at k = 1: 57.429390\n",
            "INFO - 01/22/20 04:46:00 - 0:10:11 - 4886 source words - csls_knn_10 - Precision at k = 5: 71.203438\n",
            "INFO - 01/22/20 04:46:00 - 0:10:11 - 4886 source words - csls_knn_10 - Precision at k = 10: 75.378633\n",
            "INFO - 01/22/20 04:46:03 - 0:10:14 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:46:03 - 0:10:14 - New train dictionary of 6900 pairs.\n",
            "INFO - 01/22/20 04:46:03 - 0:10:14 - Mean cosine (nn method, S2T build, 10000 max size): 0.51666\n",
            "INFO - 01/22/20 04:46:03 - 0:10:14 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:46:03 - 0:10:14 - New train dictionary of 6900 pairs.\n",
            "INFO - 01/22/20 04:46:03 - 0:10:14 - Mean cosine (nn method, S2T build, 10000 max size): 0.51666\n",
            "INFO - 01/22/20 04:46:21 - 0:10:33 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:46:21 - 0:10:33 - New train dictionary of 5330 pairs.\n",
            "INFO - 01/22/20 04:46:21 - 0:10:33 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.54934\n",
            "INFO - 01/22/20 04:46:21 - 0:10:33 - __log__:{\"n_iter\": 5, \"precision_at_1-nn\": 57.85918952108064, \"precision_at_5-nn\": 73.20916905444126, \"precision_at_10-nn\": 77.42529676627098, \"precision_at_1-csls_knn_10\": 57.42939009414654, \"precision_at_5-csls_knn_10\": 71.20343839541547, \"precision_at_10-csls_knn_10\": 75.37863282848957, \"mean_cosine-nn-S2T-10000\": 0.5166621804237366, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5493398904800415}\n",
            "INFO - 01/22/20 04:46:21 - 0:10:33 - End of iteration 5.\n",
            "                                     \n",
            "                                     \n",
            "INFO - 01/22/20 04:46:21 - 0:10:33 - * Reloading the best model from /content/dumped/debug/co4q30tuhy/best_mapping.pth ...\n",
            "INFO - 01/22/20 04:46:21 - 0:10:33 - Reloading all embeddings for mapping ...\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "INFO - 01/22/20 04:46:21 - 0:10:33 - Building the train dictionary ...\n",
            "INFO - 01/22/20 04:46:21 - 0:10:33 - New train dictionary of 5330 pairs.\n",
            "INFO - 01/22/20 04:46:21 - 0:10:33 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.54934\n",
            "INFO - 01/22/20 04:46:21 - 0:10:33 - __log__:{\"n_iter\": 5, \"precision_at_1-nn\": 57.85918952108064, \"precision_at_5-nn\": 73.20916905444126, \"precision_at_10-nn\": 77.42529676627098, \"precision_at_1-csls_knn_10\": 57.42939009414654, \"precision_at_5-csls_knn_10\": 71.20343839541547, \"precision_at_10-csls_knn_10\": 75.37863282848957, \"mean_cosine-nn-S2T-10000\": 0.5166621804237366, \"mean_cosine-csls_knn_10-S2T-10000\": 0.5493398904800415}\n",
            "INFO - 01/22/20 04:46:21 - 0:10:33 - End of iteration 5.\n",
            "                                     \n",
            "                                     \n",
            "INFO - 01/22/20 04:46:21 - 0:10:33 - * Reloading the best model from /content/dumped/debug/co4q30tuhy/best_mapping.pth ...\n",
            "INFO - 01/22/20 04:46:21 - 0:10:33 - Reloading all embeddings for mapping ...\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "tcmalloc: large alloc 4651999232 bytes == 0xcd2a000 @  0x7f8a3498b887 0x7f89c33ca363 0x7f89c33ba3df 0x7f89c33ba9f1 0x7f89c33899b3 0x7f89c33add20 0x5674fc 0x50abb3 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390\n",
            "tcmalloc: large alloc 4651999232 bytes == 0xcd2a000 @  0x7f8a3498b887 0x7f89c33ca363 0x7f89c33ba3df 0x7f89c33ba9f1 0x7f89c33899b3 0x7f89c33add20 0x5674fc 0x50abb3 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390\n",
            "INFO - 01/22/20 04:49:31 - 0:13:43 - Loaded binary model. Generating embeddings ...\n",
            "INFO - 01/22/20 04:49:31 - 0:13:43 - Loaded binary model. Generating embeddings ...\n",
            "INFO - 01/22/20 04:50:08 - 0:14:20 - Generated embeddings for 1876665 words.\n",
            "INFO - 01/22/20 04:50:08 - 0:14:20 - Generated embeddings for 1876665 words.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "tcmalloc: large alloc 4800004096 bytes == 0xcd12000 @  0x7f8a3498b887 0x7f89c33ca363 0x7f89c33ba3df 0x7f89c33ba9f1 0x7f89c33899b3 0x7f89c33add20 0x5674fc 0x50abb3 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390\n",
            "tcmalloc: large alloc 4800004096 bytes == 0xcd12000 @  0x7f8a3498b887 0x7f89c33ca363 0x7f89c33ba3df 0x7f89c33ba9f1 0x7f89c33899b3 0x7f89c33add20 0x5674fc 0x50abb3 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5aa6ec 0x50abb3 0x50d390 0x509d48 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50d390\n",
            "INFO - 01/22/20 04:53:34 - 0:17:46 - Loaded binary model. Generating embeddings ...\n",
            "INFO - 01/22/20 04:53:34 - 0:17:46 - Loaded binary model. Generating embeddings ...\n",
            "INFO - 01/22/20 04:54:30 - 0:18:42 - Generated embeddings for 2000000 words.\n",
            "INFO - 01/22/20 04:54:30 - 0:18:42 - Generated embeddings for 2000000 words.\n",
            "INFO - 01/22/20 04:54:33 - 0:18:44 - Map source embeddings to the target space ...\n",
            "/content/src/trainer.py:262: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  x = Variable(src_emb[k:k + bs], volatile=True)\n",
            "INFO - 01/22/20 04:54:33 - 0:18:44 - Map source embeddings to the target space ...\n",
            "/content/src/trainer.py:262: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  x = Variable(src_emb[k:k + bs], volatile=True)\n",
            "INFO - 01/22/20 04:54:34 - 0:18:45 - Writing source embeddings to /content/dumped/debug/co4q30tuhy/vectors-hi.txt ...\n",
            "INFO - 01/22/20 04:54:34 - 0:18:45 - Writing source embeddings to /content/dumped/debug/co4q30tuhy/vectors-hi.txt ...\n",
            "INFO - 01/22/20 05:29:11 - 0:53:22 - Writing target embeddings to /content/dumped/debug/co4q30tuhy/vectors-en.txt ...\n",
            "INFO - 01/22/20 05:29:11 - 0:53:22 - Writing target embeddings to /content/dumped/debug/co4q30tuhy/vectors-en.txt ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJh-nbuLa4gQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAhVP2pV3t5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAMX__cg3u04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_vec(emb_path, nmax=50000):\n",
        "    vectors = []\n",
        "    word2id = {}\n",
        "    with io.open(emb_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
        "      next(f)\n",
        "      for i, line in enumerate(f):\n",
        "        word, vect = line.rstrip().split(' ', 1)\n",
        "        vect = np.fromstring(vect, sep=' ')\n",
        "        assert word not in word2id, 'word found twice'\n",
        "        vectors.append(vect)\n",
        "        word2id[word] = len(word2id)\n",
        "        if len(word2id) == nmax:\n",
        "            break\n",
        "    id2word = {v: k for k, v in word2id.items()}\n",
        "    embeddings = np.vstack(vectors)\n",
        "    return embeddings, id2word, word2id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiQNknuv4OkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_path = '/content/dumped/debug/co4q30tuhy/vectors-en.txt'\n",
        "tgt_path = '/content/dumped/debug/co4q30tuhy/vectors-hi.txt'\n",
        "nmax = 50000  # maximum number of word embeddings to load\n",
        "\n",
        "src_embeddings, src_id2word, src_word2id = load_vec(src_path, nmax)\n",
        "tgt_embeddings, tgt_id2word, tgt_word2id = load_vec(tgt_path, nmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YBRx3C94a8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_nn(word, src_emb, src_id2word, tgt_emb, tgt_id2word, K=5):\n",
        "  print(\"Nearest neighbors of \\\"%s\\\":\" % word)\n",
        "  word2id = {v: k for k, v in src_id2word.items()}\n",
        "  word_emb = src_emb[word2id[word]]\n",
        "  scores = (tgt_emb / np.linalg.norm(tgt_emb, 2, 1)[:, None]).dot(word_emb / np.linalg.norm(word_emb))\n",
        "  k_best = scores.argsort()[-K:][::-1]\n",
        "  for i, idx in enumerate(k_best):\n",
        "    print('%.4f - %s' % (scores[idx], tgt_id2word[idx]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X375xgIs4pa4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "15af4e4e-c325-4209-c3a0-e9f536551884"
      },
      "source": [
        "# printing nearest neighbors in the source space\n",
        "src_word = 'cat'\n",
        "get_nn(src_word, src_embeddings, src_id2word, src_embeddings, src_id2word, K=5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nearest neighbors of \"cat\":\n",
            "1.0000 - cat\n",
            "0.8350 - cats\n",
            "0.8233 - kitty\n",
            "0.8083 - kitten\n",
            "0.7534 - feline\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LZnBLv65CvM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "1bc767c9-4b75-4c3b-82bb-04578e654283"
      },
      "source": [
        "src_word = \"पालतू\"\n",
        "get_nn(src_word, tgt_embeddings, tgt_id2word, src_embeddings, src_id2word, K=5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nearest neighbors of \"पालतू\":\n",
            "0.6495 - pet\n",
            "0.5983 - dog\n",
            "0.5621 - pets\n",
            "0.5476 - cat\n",
            "0.5440 - dogs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRrMCwwE4sGw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "d6d7517e-91b9-42c3-9f31-f2cf0a23dbd9"
      },
      "source": [
        "# printing nearest neighbors in the target space\n",
        "src_word = 'dog'\n",
        "get_nn(src_word, src_embeddings, src_id2word, tgt_embeddings, tgt_id2word, K=5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nearest neighbors of \"dog\":\n",
            "0.6683 - कुत्ते\n",
            "0.5983 - पालतू\n",
            "0.5860 - कुत्तों\n",
            "0.5648 - कुत्ता\n",
            "0.4816 - जानवर\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxFlo84B40bk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzm0YVUs5-y8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c3851796-8b2e-4bda-f5d3-2cdcb18dc00f"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2, whiten=True)  # TSNE(n_components=2, n_iter=3000, verbose=2)\n",
        "pca.fit(np.vstack([src_embeddings, tgt_embeddings]))\n",
        "print('Variance explained: %.2f' % pca.explained_variance_ratio_.sum())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variance explained: 0.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsbPoAKO5_Yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_similar_word(src_words, src_word2id, src_emb, tgt_words, tgt_word2id, tgt_emb, pca):\n",
        "\n",
        "    Y = []\n",
        "    word_labels = []\n",
        "    for sw in src_words:\n",
        "      Y.append(src_emb[src_word2id[sw]])\n",
        "      word_labels.append(sw)\n",
        "    for tw in tgt_words:\n",
        "      Y.append(tgt_emb[tgt_word2id[tw]])\n",
        "      word_labels.append(tw)\n",
        "\n",
        "      # find tsne coords for 2 dimensions\n",
        "    Y = pca.transform(Y)\n",
        "    x_coords = Y[:, 0]\n",
        "    y_coords = Y[:, 1]\n",
        "\n",
        "    # display scatter plot\n",
        "    plt.figure(figsize=(10, 8), dpi=80)\n",
        "    plt.scatter(x_coords, y_coords, marker='x')\n",
        "\n",
        "    for k, (label, x, y) in enumerate(zip(word_labels, x_coords, y_coords)):\n",
        "        color = 'blue' if k < len(src_words) else 'red'  # src words in blue / tgt words in red\n",
        "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points', fontsize=19,\n",
        "                              color=color, weight='bold')\n",
        "\n",
        "    plt.xlim(x_coords.min() - 0.2, x_coords.max() + 0.2)\n",
        "    plt.ylim(y_coords.min() - 0.2, y_coords.max() + 0.2)\n",
        "    plt.title('Visualization of the multilingual word embedding space')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta93dkZV6tCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "outputId": "301dc372-4bae-4c0f-bed7-441c091ac2b7"
      },
      "source": [
        "\n",
        "\n",
        "# get 5 random input words\n",
        "tgt_words = ['कहाँ'] \n",
        "src_words = ['where']\n",
        "\n",
        "# assert words in dictionaries\n",
        "for sw in src_words:\n",
        "    assert sw in src_word2id, '\"%s\" not in source dictionary' % sw\n",
        "for tw in tgt_words:\n",
        "    assert tw in tgt_word2id, '\"%s\" not in target dictionary' % sw\n",
        "\n",
        "plot_similar_word(src_words, src_word2id, src_embeddings, tgt_words, tgt_word2id, tgt_embeddings, pca)\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 2305 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 2305 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApUAAAIVCAYAAACA4QR/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 800x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIIO4UwVBEMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import OrderedDict\n",
        "import sys\n",
        "d2r_dict=OrderedDict([\n",
        "('क्','k'), \n",
        "('ख्','kh'), \n",
        "('ग्','g'), \n",
        "('घ्','gh'), \n",
        "('ङ्','n'), \n",
        "('च्','ch'), \n",
        "('छ्','chh'), \n",
        "('ज्','j'), \n",
        "('झ्','jh'), \n",
        "('ञ्','n'), \n",
        "('ट्','t'), \n",
        "('ठ्','th'), \n",
        "('ड्','d'), \n",
        "('ढ्','dh'), \n",
        "('ण्','n'), \n",
        "('त्','t'), \n",
        "('थ्','th'), \n",
        "('द्','d'), \n",
        "('ध्','dh'), \n",
        "('न्','n'), \n",
        "('प्','p'), \n",
        "('फ्','ph'), \n",
        "('ब्','b'), \n",
        "('भ्','bh'), \n",
        "('म्','m'), \n",
        "('य्','y'), \n",
        "('र्','r'), \n",
        "('ल्','l'), \n",
        "('व्','w'), \n",
        "('श्','s'), \n",
        "('ष्','s'), \n",
        "('स्','s'), \n",
        "('ह्','h'), \n",
        "('ष','श'), \n",
        "('स','श'), \n",
        "('का','kaa'), \n",
        "('को','ko'),\n",
        "('कौ','kau'),\n",
        "('कि','ki'),\n",
        "('की','ki'),\n",
        "('कु','ku'),\n",
        "('कू','ku'),\n",
        "('के','ke'),\n",
        "('कै','kai'),\n",
        "('कं','kum'),\n",
        "('खा','khaa'), \n",
        "('खो','kho'),\n",
        "('खौ','khau'),\n",
        "('खि','khi'),\n",
        "('खी','khi'),\n",
        "('खु','khu'),\n",
        "('खू','khu'),\n",
        "('खे','khe'),\n",
        "('खै','khai'),\n",
        "('खं','khum'),\n",
        "('गा','gaa'), \n",
        "('गो','go'),\n",
        "('गौ','gau'),\n",
        "('गि','gi'),\n",
        "('गी','gi'),\n",
        "('गु','gu'),\n",
        "('गू','gu'),\n",
        "('गे','ge'),\n",
        "('गै','gai'),\n",
        "('गं','gum'),\n",
        "('घा','ghaa'), \n",
        "('घो','gho'),\n",
        "('घौ','ghau'),\n",
        "('घि','ghi'),\n",
        "('घी','ghi'),\n",
        "('घु','ghu'),\n",
        "('घू','ghu'),\n",
        "('घे','ghe'),\n",
        "('घै','ghai'),\n",
        "('घं','ghum'),\n",
        "('ङा','naa'), \n",
        "('ङो','no'),\n",
        "('ङौ','nau'),\n",
        "('ङि','ni'),\n",
        "('ङी','ni'),\n",
        "('ङु','nu'),\n",
        "('ङू','nu'),\n",
        "('ङे','ne'),\n",
        "('ङै','nai'),\n",
        "('ङं','num'),\n",
        "('चा','chaa'), \n",
        "('चो','cho'),\n",
        "('चौ','chau'),\n",
        "('चि','chi'),\n",
        "('ची','chi'),\n",
        "('चु','chu'),\n",
        "('चू','chu'),\n",
        "('चे','che'),\n",
        "('चै','chai'),\n",
        "('चं','chum'),\n",
        "('छा','chhaa'), \n",
        "('छो','chho'),\n",
        "('छौ','chhau'),\n",
        "('छि','chhi'),\n",
        "('छी','chhi'),\n",
        "('छु','chhu'),\n",
        "('छू','chhu'),\n",
        "('छे','chhe'),\n",
        "('छै','chhai'),\n",
        "('छं','chhum'),\n",
        "('जा','jaa'), \n",
        "('जो','jo'),\n",
        "('जौ','jau'),\n",
        "('जि','ji'),\n",
        "('जी','ji'),\n",
        "('जु','ju'),\n",
        "('जू','ju'),\n",
        "('जे','je'),\n",
        "('जै','jai'),\n",
        "('जं','jum'),\n",
        "('झा','jhaa'), \n",
        "('झो','jho'),\n",
        "('झौ','jhau'),\n",
        "('झि','jhi'),\n",
        "('झी','jhi'),\n",
        "('झु','jhu'),\n",
        "('झू','jhu'),\n",
        "('झे','jhe'),\n",
        "('झै','jhai'),\n",
        "('झं','jhum'),\n",
        "('ञा','naa'), \n",
        "('ञो','no'),\n",
        "('ञौ','nau'),\n",
        "('ञि','ni'),\n",
        "('ञी','ni'),\n",
        "('ञु','nu'),\n",
        "('ञू','nu'),\n",
        "('ञे','ne'),\n",
        "('ञै','nai'),\n",
        "('ञं','num'),\n",
        "('टा','taa'), \n",
        "('टो','to'),\n",
        "('टौ','tau'),\n",
        "('टि','ti'),\n",
        "('टी','ti'),\n",
        "('टु','tu'),\n",
        "('टू','tu'),\n",
        "('टे','te'),\n",
        "('टै','tai'),\n",
        "('टं','tum'),\n",
        "('ठा','thaa'), \n",
        "('ठो','tho'),\n",
        "('ठौ','thau'),\n",
        "('ठि','thi'),\n",
        "('ठी','thi'),\n",
        "('ठु','thu'),\n",
        "('ठू','thu'),\n",
        "('ठे','the'),\n",
        "('ठै','thai'),\n",
        "('ठं','thum'),\n",
        "('डा','daa'), \n",
        "('डो','do'),\n",
        "('डौ','dau'),\n",
        "('डि','di'),\n",
        "('डी','di'),\n",
        "('डु','du'),\n",
        "('डू','du'),\n",
        "('डे','de'),\n",
        "('डै','dai'),\n",
        "('डं','dum'),\n",
        "('ढा','dhaa'), \n",
        "('ढो','dho'),\n",
        "('ढौ','dha'),\n",
        "('ढि','dhi'),\n",
        "('ढी','dhi'),\n",
        "('ढु','dhu'),\n",
        "('ढू','dhu'),\n",
        "('ढे','dhe'),\n",
        "('ढै','dhai'),\n",
        "('ढं','dhum'),\n",
        "('ता','taa'), \n",
        "('तो','to'),\n",
        "('तौ','tau'),\n",
        "('ति','ti'),\n",
        "('ती','ti'),\n",
        "('तु','tu'),\n",
        "('तू','tu'),\n",
        "('ते','te'),\n",
        "('तै','tai'),\n",
        "('तं','tum'),\n",
        "('था','thaa'), \n",
        "('थो','tho'),\n",
        "('थौ','thau'),\n",
        "('थि','thi'),\n",
        "('थी','thi'),\n",
        "('थु','thu'),\n",
        "('थू','thu'),\n",
        "('थे','the'),\n",
        "('थै','thai'),\n",
        "('थं','thum'),\n",
        "('दा','daa'), \n",
        "('दो','do'),\n",
        "('दौ','dau'),\n",
        "('दि','di'),\n",
        "('दी','di'),\n",
        "('दु','du'),\n",
        "('दू','du'),\n",
        "('दे','de'),\n",
        "('दै','dai'),\n",
        "('दं','dum'),\n",
        "('धा','dhaa'), \n",
        "('धो','dho'),\n",
        "('धौ','dhau'),\n",
        "('धि','dhi'),\n",
        "('धी','dhi'),\n",
        "('धु','dhu'),\n",
        "('धू','dhu'),\n",
        "('धे','dhe'),\n",
        "('धै','dhai'),\n",
        "('धं','dhum'),\n",
        "('ना','naa'), \n",
        "('नो','no'),\n",
        "('नौ','nau'),\n",
        "('नि','ni'),\n",
        "('नी','ni'),\n",
        "('नु','nu'),\n",
        "('नू','nu'),\n",
        "('ने','ne'),\n",
        "('नै','nai'),\n",
        "('नं','num'),\n",
        "('पा','paa'), \n",
        "('पो','po'),\n",
        "('पौ','pau'),\n",
        "('पि','pi'),\n",
        "('पी','pi'),\n",
        "('पु','pu'),\n",
        "('पू','pu'),\n",
        "('पे','pe'),\n",
        "('पै','pai'),\n",
        "('पं','pum'),\n",
        "('फा','phaa'), \n",
        "('फो','pho'),\n",
        "('फौ','phau'),\n",
        "('फि','phi'),\n",
        "('फी','phi'),\n",
        "('फु','phu'),\n",
        "('फू','phu'),\n",
        "('फे','phe'),\n",
        "('फै','phai'),\n",
        "('फं','phum'),\n",
        "('बा','baa'), \n",
        "('बो','bo'),\n",
        "('बौ','bau'),\n",
        "('बि','bi'),\n",
        "('बी','bi'),\n",
        "('बु','bu'),\n",
        "('बू','bu'),\n",
        "('बे','be'),\n",
        "('बै','bai'),\n",
        "('बं','bum'),\n",
        "('भा','bhaa'), \n",
        "('भो','bho'),\n",
        "('भौ','bhau'),\n",
        "('भि','bhi'),\n",
        "('भी','bhi'),\n",
        "('भु','bhu'),\n",
        "('भू','bhu'),\n",
        "('भे','bhe'),\n",
        "('भै','bhai'),\n",
        "('भं','bhum'),\n",
        "('मा','maa'), \n",
        "('मो','mo'),\n",
        "('मौ','mau'),\n",
        "('मि','mi'),\n",
        "('मी','mi'),\n",
        "('मु','mu'),\n",
        "('मू','mu'),\n",
        "('मे','me'),\n",
        "('मै','mai'),\n",
        "('मं','mum'),\n",
        "('या','yaa'), \n",
        "('यो','yo'),\n",
        "('यौ','yau'),\n",
        "('यि','yi'),\n",
        "('यी','yi'),\n",
        "('यु','yu'),\n",
        "('यू','yu'),\n",
        "('ये','ye'),\n",
        "('यै','yai'),\n",
        "('यं','yum'),\n",
        "('रा','raa'), \n",
        "('रो','ro'),\n",
        "('रौ','rau'),\n",
        "('रि','ri'),\n",
        "('री','ri'),\n",
        "('रु','ru'),\n",
        "('रू','ru'),\n",
        "('रे','re'),\n",
        "('रै','rai'),\n",
        "('रं','rum'),\n",
        "('ला','laa'), \n",
        "('लो','lo'),\n",
        "('लौ','lau'),\n",
        "('लि','li'),\n",
        "('ली','li'),\n",
        "('लु','lu'),\n",
        "('लू','lu'),\n",
        "('ले','le'),\n",
        "('लै','lai'),\n",
        "('लं','lum'),\n",
        "('वा','waa'), \n",
        "('वो','wo'),\n",
        "('वौ','wau'),\n",
        "('वि','wi'),\n",
        "('वी','wi'),\n",
        "('वु','wu'),\n",
        "('वू','wu'),\n",
        "('वे','we'),\n",
        "('वै','wai'),\n",
        "('वं','wum'),\n",
        "('शा','saa'), \n",
        "('शो','so'),\n",
        "('शौ','sau'),\n",
        "('शि','si'),\n",
        "('शी','si'),\n",
        "('शु','su'),\n",
        "('शू','su'),\n",
        "('शे','se'),\n",
        "('शै','sai'),\n",
        "('शं','sum'),\n",
        "('हा','haa'), \n",
        "('हो','ho'),\n",
        "('हौ','hau'),\n",
        "('हि','hi'),\n",
        "('ही','hi'),\n",
        "('हु','hu'),\n",
        "('हू','hu'),\n",
        "('हे','he'),\n",
        "('है','hai'),\n",
        "('हं','hum'),\n",
        "('क','ka'), \n",
        "('ख','kha'), \n",
        "('ग','ga'), \n",
        "('घ','gha'), \n",
        "('ङ','na'), \n",
        "('च','cha'), \n",
        "('छ','chha'), \n",
        "('ज','ja'), \n",
        "('झ','jha'), \n",
        "('ञ','na'), \n",
        "('ट','ta'), \n",
        "('ठ','tha'), \n",
        "('ड','da'), \n",
        "('ढ','dha'), \n",
        "('ण','na'), \n",
        "('त','ta'), \n",
        "('थ','tha'), \n",
        "('द','da'), \n",
        "('ध','dha'), \n",
        "('न','na'), \n",
        "('प','pa'), \n",
        "('फ','pha'), \n",
        "('ब','ba'), \n",
        "('भ','bha'), \n",
        "('म','ma'), \n",
        "('य','ya'), \n",
        "('र','ra'), \n",
        "('ल','la'), \n",
        "('व','wa'), \n",
        "('श','sa'), \n",
        "('ष','श'), \n",
        "('स','श'), \n",
        "('ह','ha'),\n",
        "('ँ','n'),\n",
        "('ं','m'),\n",
        "('ः','h'),\n",
        "('अ','a'), \n",
        "('आ','a'), \n",
        "('इ','i'), \n",
        "('ई','i'), \n",
        "('उ','u'), \n",
        "('ऊ','u'), \n",
        "('ऋ','ri'), \n",
        "('ए','e'), \n",
        "('ऐ','ai'), \n",
        "('ओ','o'), \n",
        "('औ','au'), \n",
        "('ा','a'), \n",
        "('ि','i'), \n",
        "('ी','i'), \n",
        "('ु','u'), \n",
        "('ू','u'), \n",
        "('ृ','ri'), \n",
        "('े','e'), \n",
        "('ै','ai'), \n",
        "('ो','o'), \n",
        "('ौ','au')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXGc4xKIDAI8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "7498a7a1-abf0-46ee-d401-c85d0edb3028"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7iImWO57NJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "88765099-a17b-4250-c20c-ae1f09c87638"
      },
      "source": [
        "for i in list(tgt_word2id.keys())[:20]:\n",
        "  text = i\n",
        "  for key,value in d2r_dict.items():\n",
        "      \ttext=text.replace(key,value)  \n",
        "  print(i,text)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "के ke\n",
            "। ।\n",
            "है hai\n",
            ", ,\n",
            "में mem\n",
            "</s> </s>\n",
            "' '\n",
            "की ki\n",
            ". .\n",
            "का kaa\n",
            "से se\n",
            "- -\n",
            "और aura\n",
            "को ko\n",
            "? ?\n",
            "हैं haim\n",
            "> >\n",
            "पर para\n",
            ") )\n",
            "( (\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-kJr6gBE4YQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a527732-b524-4b65-c4c7-4863b61b24d3"
      },
      "source": [
        "tgt_embeddings[tgt_word2id[\"और\"]]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7.1900e-03, -1.4970e-02, -1.6970e-02,  1.0660e-02,  1.4060e-02,\n",
              "        5.3270e-02, -9.0390e-02, -1.8260e-02, -7.5000e-02,  1.4700e-03,\n",
              "        2.1410e-02, -3.1960e-02,  2.2460e-02, -3.1400e-03, -5.1300e-02,\n",
              "       -1.0444e-01, -1.2590e-02, -3.7050e-02, -7.0190e-02, -3.6510e-02,\n",
              "       -1.9800e-03,  1.4570e-02, -5.6600e-03, -1.4460e-02, -2.3940e-02,\n",
              "       -1.9840e-02,  7.2460e-02,  2.2940e-02,  2.6730e-02,  7.5300e-02,\n",
              "        1.6800e-03, -7.3920e-02,  6.6620e-02,  1.6884e-01, -2.7050e-02,\n",
              "       -1.2560e-02,  4.3620e-02,  2.0010e-02,  2.9420e-02, -3.0110e-02,\n",
              "       -4.3000e-04,  4.8840e-02, -2.9690e-02, -3.5320e-02,  7.6470e-02,\n",
              "       -1.0479e-01,  6.7360e-02,  7.3850e-02, -8.4310e-02,  2.1250e-02,\n",
              "        1.9130e-02,  2.5070e-02, -3.5540e-02,  4.9360e-02, -8.9360e-02,\n",
              "       -1.3772e-01,  3.6800e-03,  7.3090e-02,  2.7530e-02,  4.0400e-03,\n",
              "        3.4870e-02, -5.0210e-02, -8.8000e-03, -8.6750e-02,  8.1970e-02,\n",
              "        4.2300e-02, -1.7740e-02,  2.2590e-02,  4.0290e-02,  7.7560e-02,\n",
              "        1.2074e-01,  2.1040e-02,  9.5040e-02,  6.3170e-02,  2.7360e-02,\n",
              "       -9.7800e-03,  4.7420e-02, -7.1660e-02, -4.4190e-02, -8.1400e-02,\n",
              "       -5.7600e-03,  1.8300e-02,  4.3100e-03, -5.3700e-03, -6.7980e-02,\n",
              "        1.6100e-03,  2.8910e-02, -5.9500e-02, -1.0541e-01, -7.5650e-02,\n",
              "       -8.5000e-04, -3.5080e-02,  5.4370e-02,  4.8380e-02,  8.8030e-02,\n",
              "        6.7600e-03, -7.6860e-02, -1.9330e-02, -6.2280e-02,  4.3580e-02,\n",
              "       -3.1170e-02,  1.0330e-02, -5.3500e-02, -5.0660e-02, -1.2500e-02,\n",
              "       -6.5460e-02, -9.5290e-02,  9.8390e-02,  7.2300e-03,  1.5260e-02,\n",
              "       -4.2190e-02, -7.0380e-02,  3.9910e-02,  7.4120e-02,  2.6100e-03,\n",
              "        1.0128e-01,  7.1400e-03,  6.2800e-03, -5.5100e-03, -7.9180e-02,\n",
              "        5.6350e-02, -2.1440e-02, -5.5360e-02,  5.1220e-02,  7.9360e-02,\n",
              "        1.3644e-01,  5.4210e-02,  5.3240e-02,  4.2850e-02,  1.4930e-02,\n",
              "       -5.6500e-02,  7.1200e-03, -7.2260e-02, -8.3010e-02, -5.8440e-02,\n",
              "       -1.0272e-01, -1.6017e-01,  6.9220e-02,  3.2600e-02,  2.1300e-03,\n",
              "       -1.4680e-02, -3.6210e-02, -5.0900e-03,  1.1470e-01,  2.8700e-03,\n",
              "        5.7450e-02, -3.5149e-01, -3.3960e-02, -4.9500e-03,  5.4370e-02,\n",
              "        4.5530e-02, -5.0020e-02, -1.1553e-01,  7.2490e-02, -3.3000e-03,\n",
              "        3.2040e-02,  5.1110e-02, -5.9000e-02, -1.3671e-01, -4.7120e-02,\n",
              "        5.3350e-02, -5.5780e-02, -2.0600e-02,  5.6310e-02,  1.1690e-01,\n",
              "       -1.0940e-02, -1.3930e-02,  4.1490e-02, -4.6330e-02,  2.4390e-02,\n",
              "        2.5000e-04, -4.0020e-02,  3.5900e-03,  1.5626e-01,  8.6100e-03,\n",
              "       -1.2405e-01,  2.9430e-02, -9.0200e-03,  9.5290e-02, -1.2140e-02,\n",
              "       -1.8980e-02,  9.8120e-02,  4.4030e-02, -2.9540e-02,  7.7080e-02,\n",
              "        4.8830e-02,  2.2370e-02,  3.7340e-02, -3.0670e-02, -4.2630e-02,\n",
              "        8.9500e-03,  1.7950e-02, -3.0760e-02,  1.2950e-02, -1.8850e-02,\n",
              "       -3.9820e-02,  6.8500e-02,  2.0970e-02,  4.0000e-02,  1.5180e-02,\n",
              "        6.7830e-02,  8.7590e-02,  7.8490e-02,  1.4360e-02, -1.5970e-02,\n",
              "        1.7450e-02,  2.3380e-02, -3.7270e-02, -4.8330e-02,  7.4320e-02,\n",
              "       -1.0490e-02,  1.1199e-01, -1.6740e-02, -4.4550e-02, -7.6160e-02,\n",
              "        6.3360e-02,  6.9830e-02,  6.1600e-03,  9.4810e-02,  4.8000e-02,\n",
              "       -1.4980e-02,  4.5370e-02, -3.9110e-02, -1.2180e-02,  2.2000e-02,\n",
              "        1.8570e-02,  7.5910e-02, -5.2960e-02, -6.6600e-02, -7.6700e-03,\n",
              "        6.7530e-02, -9.3650e-02,  5.1550e-02, -2.0730e-02,  6.0480e-02,\n",
              "       -4.5490e-02,  7.9200e-03,  4.1400e-03,  3.7780e-02, -2.0740e-02,\n",
              "       -2.9000e-04, -7.4130e-02,  5.8080e-02, -9.6190e-02,  5.4167e-01,\n",
              "       -3.3870e-02, -3.9500e-03, -2.1560e-02,  1.7250e-02,  1.3461e-01,\n",
              "       -7.3420e-02,  9.7400e-03,  2.2220e-02,  7.1300e-03, -2.7670e-02,\n",
              "       -9.9970e-02, -1.3740e-02,  6.3330e-02,  4.7200e-03,  5.5970e-02,\n",
              "       -7.0900e-03,  1.0689e-01, -2.1900e-03,  3.3810e-02, -1.0996e-01,\n",
              "        6.8350e-02, -2.3150e-02,  3.6110e-02, -1.0673e-01,  1.6140e-02,\n",
              "       -3.7890e-02, -1.2780e-02,  2.0000e-05,  1.9890e-02,  5.5960e-02,\n",
              "        1.8900e-03,  4.0470e-02, -1.1009e-01,  3.2800e-02,  5.4360e-02,\n",
              "       -9.3910e-02,  1.5828e-01, -1.7673e-01,  1.6550e-02,  6.4700e-03,\n",
              "       -2.6690e-02, -4.2630e-02,  6.1680e-02, -4.7650e-02, -5.1630e-02,\n",
              "       -3.7580e-02,  7.0860e-02, -2.7530e-02, -4.0000e-05,  1.8050e-02,\n",
              "        3.7690e-02, -5.9760e-02,  7.3890e-02, -6.8110e-02,  4.3420e-02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxxrJ_bB7hy4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f74d8fe-6c9f-4863-d0b4-53f20751ddc5"
      },
      "source": [
        "src_embeddings[src_word2id[\"where\"]]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.5600e-02,  5.4420e-02, -2.1710e-02,  7.3300e-03, -7.1720e-02,\n",
              "        2.3470e-02,  3.4710e-02, -6.1200e-03,  5.7000e-02, -3.2210e-02,\n",
              "       -2.8370e-02, -3.0000e-05,  2.0880e-02,  5.7500e-03, -7.4400e-03,\n",
              "       -3.0000e-05,  5.2270e-02,  1.2190e-02,  2.3090e-02,  5.8270e-02,\n",
              "       -2.2100e-03,  3.6800e-03,  2.9560e-02, -3.2850e-02, -5.4510e-02,\n",
              "       -2.4050e-02, -1.5540e-02, -9.6900e-03, -1.4360e-02, -2.0740e-02,\n",
              "       -5.8160e-02, -2.5250e-02, -3.1780e-02, -1.1830e-02, -3.6710e-02,\n",
              "       -1.6440e-02,  1.4690e-02, -4.1000e-02, -1.1650e-02, -2.4300e-03,\n",
              "        4.7800e-02, -5.3810e-02,  2.4510e-02,  1.7550e-02,  1.8010e-02,\n",
              "        4.7040e-02, -3.3730e-02,  4.8800e-02, -1.0260e-02,  4.8950e-02,\n",
              "       -1.7410e-02,  8.8000e-04, -2.3300e-03, -1.4690e-02, -3.3710e-02,\n",
              "       -3.8230e-02, -4.0720e-02, -1.0000e-03,  1.2670e-02, -4.1650e-02,\n",
              "        5.4420e-02,  1.1700e-03, -4.1160e-02,  2.1260e-02, -2.5340e-02,\n",
              "       -1.4930e-02, -2.0610e-02, -4.0760e-02, -1.7600e-02,  2.3750e-02,\n",
              "        4.6430e-02,  2.0100e-02,  2.7070e-02, -2.7110e-02,  1.0300e-03,\n",
              "       -4.0310e-02, -2.7860e-02, -2.2300e-02,  7.5500e-03,  5.7820e-02,\n",
              "       -9.5100e-03,  1.0910e-02, -2.9380e-02,  4.2420e-02, -4.9040e-02,\n",
              "        1.6260e-02, -4.4300e-02, -6.3390e-02,  1.1057e-01, -2.2390e-02,\n",
              "       -3.6550e-02, -4.4490e-02,  8.1300e-03, -2.2110e-02,  1.2546e-01,\n",
              "       -3.1210e-02, -1.4620e-02, -3.0380e-02,  4.9900e-03,  2.7950e-02,\n",
              "        1.9090e-02, -2.0700e-02,  1.7390e-02, -8.4730e-02,  3.9710e-02,\n",
              "        8.8900e-03, -2.0200e-02, -3.1200e-02, -3.6370e-02,  7.7170e-02,\n",
              "        2.1440e-02, -3.2300e-03,  2.7030e-02,  5.3190e-02, -1.5550e-02,\n",
              "       -4.1960e-02, -7.9620e-02,  5.9800e-03,  1.4470e-02,  8.0700e-03,\n",
              "       -4.3390e-02,  5.2180e-02, -3.6970e-02,  1.7010e-02,  5.7350e-02,\n",
              "        1.9800e-02,  2.0780e-02, -2.9950e-02,  1.1510e-02,  1.1529e-01,\n",
              "        5.3700e-03,  2.4000e-04,  7.2500e-02, -1.8990e-02,  3.8020e-02,\n",
              "       -1.1200e-02, -6.5730e-02,  5.1950e-02, -1.0450e-02,  4.9220e-02,\n",
              "        1.8600e-02, -1.8070e-02,  2.1600e-03,  1.6000e-03, -1.1600e-02,\n",
              "        6.8890e-02, -1.4600e-01,  3.5590e-02,  2.0900e-02,  8.5000e-04,\n",
              "       -2.9410e-02,  1.0800e-02,  3.0960e-02, -1.3980e-02,  4.7660e-02,\n",
              "        1.4370e-02,  8.6150e-02,  3.9240e-02,  1.6760e-02,  3.1560e-02,\n",
              "       -6.7740e-02, -3.6500e-03,  2.2710e-02, -5.2780e-02,  3.7960e-02,\n",
              "        2.0590e-02,  3.0620e-02, -3.3400e-03, -4.1000e-04, -1.8070e-02,\n",
              "        7.6600e-03, -3.1650e-02,  8.8400e-03,  1.4500e-03, -6.1860e-02,\n",
              "        3.5240e-02,  1.7450e-02,  2.1670e-02,  2.5650e-02, -7.6570e-02,\n",
              "        5.8190e-02, -1.2100e-03,  6.6200e-03,  3.7960e-02,  3.5150e-02,\n",
              "        6.5340e-02, -5.6750e-02, -6.7900e-03,  3.5350e-02, -3.5410e-02,\n",
              "       -4.9690e-02, -5.4720e-02,  4.7000e-02,  3.0980e-02, -1.5640e-02,\n",
              "       -3.3240e-02,  2.5520e-02, -8.1120e-02,  6.4900e-03,  2.7260e-02,\n",
              "       -2.6330e-02,  4.5500e-03, -2.5000e-02, -1.4560e-02,  4.8500e-03,\n",
              "       -3.3800e-03, -9.8480e-02,  1.8300e-02,  9.2600e-03, -2.1210e-02,\n",
              "        2.7060e-02, -3.8950e-02, -8.1430e-02,  2.3150e-02, -8.8000e-04,\n",
              "       -2.6890e-02,  1.3520e-02, -1.8270e-02, -2.1480e-02,  8.7210e-02,\n",
              "       -8.2600e-03,  5.2110e-02,  3.5890e-02,  1.0261e-01, -2.6560e-02,\n",
              "       -1.3580e-02,  3.5260e-02, -3.8190e-02,  2.5860e-02, -3.4170e-02,\n",
              "       -5.7150e-02,  1.5720e-02,  3.8160e-02,  3.5750e-02,  2.1500e-03,\n",
              "       -1.8207e-01,  1.3150e-02, -9.4000e-04, -4.7130e-02,  1.2890e-02,\n",
              "        1.7590e-02,  2.2450e-02, -3.3290e-02, -1.1415e-01,  2.5013e-01,\n",
              "       -1.4350e-02,  2.8920e-02, -3.3420e-02,  2.9700e-02,  5.3020e-02,\n",
              "        8.7300e-03, -2.2860e-02,  4.6100e-03, -2.6550e-02,  4.0480e-02,\n",
              "        3.4370e-02, -9.5540e-02, -8.8400e-03,  1.3800e-03,  3.9200e-02,\n",
              "       -2.4010e-02,  4.0600e-03, -2.4280e-02, -6.4650e-02, -7.7780e-02,\n",
              "        4.6200e-02,  1.9020e-02,  3.8000e-03, -3.8700e-03, -6.1510e-02,\n",
              "       -5.6870e-02,  1.2010e-02, -7.7590e-02, -7.6340e-02, -1.4208e-01,\n",
              "       -5.7670e-02, -4.5060e-02, -3.6690e-02,  3.0500e-03,  4.9570e-02,\n",
              "        1.5370e-02,  1.9460e-02, -1.6312e-01, -1.0300e-03,  1.7220e-02,\n",
              "       -2.2140e-02,  4.6930e-02, -2.8080e-02, -3.8020e-02,  2.9220e-02,\n",
              "        2.3290e-02, -3.0080e-02, -7.1620e-02,  1.7990e-02, -3.8230e-02,\n",
              "        2.8880e-02,  1.5320e-02,  5.5740e-02, -4.3400e-03,  3.2350e-02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptmo0Zh0EgmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}