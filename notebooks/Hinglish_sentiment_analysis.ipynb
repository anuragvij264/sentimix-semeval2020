{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hinglish_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVFUzDDo6Y5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "2e28643f-0ad3-4946-cff5-38a04564e536"
      },
      "source": [
        "! git clone '''https://username:password@github.com/anuragvij264/SemEval2020.git'''\n",
        "! cd SemEval2020 && git checkout Bidirectional_LSTM_ATTN_added\n",
        "! mv SemEval2020/* ./"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SemEval2020'...\n",
            "remote: Enumerating objects: 216, done.\u001b[K\n",
            "remote: Counting objects: 100% (216/216), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n",
            "remote: Total 216 (delta 109), reused 182 (delta 75), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (216/216), 7.89 MiB | 9.76 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n",
            "Branch 'Bidirectional_LSTM_ATTN_added' set up to track remote branch 'Bidirectional_LSTM_ATTN_added' from 'origin'.\n",
            "Switched to a new branch 'Bidirectional_LSTM_ATTN_added'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdmn9I_SuD-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_download_link = \"https://docs.google.com/uc?export=download&id=1s_PR0GOwhpiXx4GSO8j0utaC7exw7E0M\" \n",
        "! wget -r --no-check-certificate \"$file_download_link\"  -O embeddings.zip\n",
        "! unzip embeddings.zip\n",
        "! mv drive/My\\ Drive/SemEval2020/embeddings/ bin/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNIyWJVPMHAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_download_link = \"https://docs.google.com/uc?export=download&id=1v52uBG0XiiQN1kI02GDzTzMcC5193sdB\"\n",
        "! wget -r --no-check-certificate \"$file_download_link\"  -O vocab.pth\n",
        "! cp vocab.pth /content/bin/vocab.pth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu7S1z6wFcGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "fa0a0aca-6205-4cb3-aa9a-e7ecad0d8c89"
      },
      "source": [
        "!python3 train.py"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "  0% 0/15 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 126, in <module>\n",
            "    train(net, train_loader, valid_loader)\n",
            "  File \"train.py\", line 64, in train\n",
            "    prediction = model(inputs, input_emoji, input_profanity)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/nn_model/LSTM_attn.py\", line 44, in forward\n",
            "    input_sentence = self.word_embeddings(input_sentence.to(dtype=torch.long))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\", line 114, in forward\n",
            "    self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 1484, in embedding\n",
            "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
            "RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ2npMW9s31I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}